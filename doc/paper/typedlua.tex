\documentclass[preprint]{sig-alternate}

\usepackage[utf8]{inputenc}
\usepackage[numbers]{natbib}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{url}

\newcommand{\Any}{\mathbf{any}}
\newcommand{\Top}{\mathbf{value}}
\newcommand{\Nil}{\mathbf{nil}}
\newcommand{\False}{\mathbf{false}}
\newcommand{\True}{\mathbf{true}}
\newcommand{\Boolean}{\mathbf{boolean}}
\newcommand{\Number}{\mathbf{number}}
\newcommand{\String}{\mathbf{string}}
\newcommand{\Void}{\mathbf{void}}
\newcommand{\Const}{\mathbf{const}}

\def\dstart{\hbox to \hsize{\vrule depth 4pt\hrulefill\vrule depth 4pt}}
\def\dend{\hbox to \hsize{\vrule height 4pt\hrulefill\vrule height 4pt}}

\begin{document}

\conferenceinfo{Dyla}{'14, Edinburgh, UK} 

\title{Typed Lua: An Optional Type System for Lua}

\numberofauthors{3}

\author{
\alignauthor
Andr√© Murbach Maidl\\
  \affaddr{PUC-Rio}\\
  \affaddr{Rio de Janeiro, Brazil}\\
  \email{amaidl@inf.puc-rio.br}
\alignauthor
Fabio Mascarenhas\\
  \affaddr{UFRJ}\\
  \affaddr{Rio de Janeiro, Brazil}\\
  \email{fabiom@dcc.ufrj.br}
\alignauthor
Roberto Ierusalimschy\\
  \affaddr{PUC-Rio}\\
  \affaddr{Rio de Janeiro, Brazil}\\
  \email{roberto@inf.puc-rio.br}
}

\date{June 12th 2014}

\maketitle

\begin{abstract}
\end{abstract}

\category{D.3.3}
         {Programming Languages}
         {Language Constructs and Features}
\category{D.2.3}
         {Programming Languages}
         {Coding Tools and Techniques}
         [Object-oriented programming]

\terms{Languages,Verification}

\keywords{Type Systems, Lua}

\section{Introduction} \label{sec:intro}

Dynamically typed languages such as Lua avoid static types in favor of
run-time {\em type tags} that classify the values they compute, and
their implementations use these tags to perform run-time (or dynamic)
checking and guarantee that only valid operations are
performed~\citep{pierce2002tpl}.

The absence of static types means that programmers do not need to
bother about abstracting types that might require a complex type
system and type checker to validate, leading to simpler and more flexible
languages and implementations. But this absence may also hide bugs
that will be caught only after deployment if programmers do not properly
test their code.

In contrast, static type checking helps programmers detect many 
bugs during the development phase. Static types also provide a
conceptual framework that helps programmers define modules
and interfaces that can be combined to structure the development
of large programs.

The early error detection and better program structure afforded by
static type checking can lead programmers to migrate their code from
a dynamically typed to a statically typed language, once their simple
scripts become complex programs~\citep{tobin-hochstadt2006ims}.
As this migration involves languages with different syntax and
semantics, it requires a complete rewrite of existing programs intead
of incremental evolution from dynamic to static types.

Ideally, programming languages should offer programmers the
option to choose between static and dynamic typing:
\textit{optional type systems}~\citep{bracha2004pluggable} and
\textit{gradual typing}~\citep{siek2006gradual} are two approaches
that offer programmers the option to use type annotations where static
typing is needed, incrementally migrating a system from dynamic
to static types. The difference between these two approaches is the
way they treat run-time semantics: while optional type systems
do not affect the run-time semantics,
gradual typing uses run-time checks to ensure that dynamically typed
code does not violate the invariants of statically typed code.

In this work we outline the design of Typed Lua:
an optional type system for Lua that is complex enough to
preserve some of the idioms that Lua programmers are already used to,
while adding new constructs that help programmers structure Lua
programs.


Lua is a small imperative scripting language with first-class
functions (with proper lexical scoping) where the main data
structure is the {\em table}, an associative array that can
play the part of arrays, records, maps, objects, etc.
with syntactic sugar and metaprogramming through operator overloading built into
the language. Unlike other scripting languages, Lua has very
limited coercion among different data types.

The primary use of Lua has always been as an embedded language
for configuration and extension of other applications.
Lua prefers to provide mechanisms instead of fixed policies
for structuring programs, and even features
such as a module system and object orientation are a matter of 
convention instead of built into the language.
The result is a fragmented ecosystem of libraries, and
different ideas among Lua programmers on how they should use
the language features and how they should structure programs.

The lack of standard policies
is a challenge for the design of a static type system for the Lua
language. The design of Typed Lua is informed by a (mostly
automated) survey of Lua idioms used in a large corpus of Lua
libraries, instead of relying just on the semantics of the
language.

Typed Lua allows statically typed Lua code to coexist and
interact with  ynamically typed code. The Typed Lua compiler
warns the programmer about type errors, but always generates
Lua code that runs in unmodified Lua implementations. The
programmer can enjoy some of the benefits of static types even
without converting existing Lua modules to typed Lua:
a dynamically typed module can export a statically typed
interface, and statically typed users of the module will have
their use of the module checked by the compiler.

Unlike gradual type systems, Typed Lua does not insert run-time
checks between dynamically and statically typed parts of the
program. Unlike some optional type systems, the statically
typed subset of Typed Lua is sound by design, so a later
version of the Typed Lua compiler can swicth to gradual
instead of just optional typing.

We cover the main parts of the design, along with
how they relate to Lua, in Sections~\ref{sec:atomic}
through~\ref{sec:classes}. Section~\ref{sec:review} reviews
related work on mixing static and dynamic typing in the same
language. Finally, Section~\ref{sec:con} gives some
concluding remarks and future extensions for Typed Lua.

\section{Atomic Types and Functions}
\label{sec:atomic}

Lua values can have one of eight {\em tags}: {\em nil}, {\em boolean},
{\em number}, {\em string}, {\em function}, {\em table}, {\em userdata},
and {\em thread}. We will see how Typed Lua assigns types to
values of the first five in this section.

Figure~\ref{fig:typelang} gives the abstract syntax of Typed Lua
types. Only {\em first-class types} correspond to actual Lua
values; {\em second-class types} correspond to expression lists,
and Typed Lua uses them to type multiple assignment and function
application. Types are ordered by a subtype relationship, where
any first-class type is a subtype of $\Top$.

The {\em dynamic type} $\Any$ allows dynamically typed code to
interoperate with statically typed code; it is a subtype of $\Top$, but
neither a supertype nor a subtype of any other type. We relate $\Any$
to other types with the {\em consistency} and {\em consistent-subtype}
relationships used by gradual type systems. In practice, we can
pass a value of the dynamic type anytime we want a value of some
other type, and can pass any value where a value of the dynamic type
is expected, but these operations are tracked by the type system,
and the programmer can choose to be warned about them.

\begin{figure}[!ht]
\textbf{Type Language}\\
\dstart
$$
\begin{array}{rlr}
\multicolumn{3}{c}{\textbf{First-class types}} \\
T ::= & \;\; L & \textit{literal types}\\
& | \; B & \textit{base types}\\
& | \; \Top & \textit{top type}\\
& | \; \Any & \textit{dynamic type}\\
& | \; T \cup T & \textit{disjoint union types}\\
& | \; S \rightarrow S & \textit{function types}\\
& | \; \{F, ..., F\} & \textit{table types}\\
& | \; X & \textit{type variables}\\
& | \; \mu X.T & \textit{recursive types}\\
& | \; X_i & \textit{projection types}\\
L ::= & \multicolumn{2}{l}{\False \; | \; \True \; | \; {<}{\it number}{>} \; | \; {<}{\it string}{>} } \\
B ::= & \multicolumn{2}{l}{\Nil \; | \; \Boolean \; | \; \Number \; | \; \String} \\
F ::= & T:T \; | \; \Const \; T:T & \textit{field types} \\
\multicolumn{3}{c}{} \\
\multicolumn{3}{c}{\textbf{Second-class types}} \\
S ::= &  \multicolumn{2}{l}{\Void \; |\; V \; | \; S \cup S} \\
V ::= & \;\; T & \\
& | \; T* & \textit{vararg types}\\
& | \; T \times V & \textit{tuple types}
\end{array}
$$
\dend
\caption{Abstract syntax of Typed Lua types}
\label{fig:typelang}
\end{figure}

Typed Lua allows optional type annotations in variable function
declarations. It assigns the dynamic type to any parameter that
does not have an type annotation, but assigns more precise
types to unnanotated variables, based on the type of the
expression that gives the initial value of the variable.

In the following example, we use type annotations in a function
declaration but do not use type annotations in the declaration of a
local variable:
\begin{verbatim}
    local function factorial(n: number): number
      if n == 0 then
        return 1
      else
        return n * factorial(n - 1)
      end
    end
    local x = 5
    print(factorial(x))
\end{verbatim}

The compiler assigns the type $\Number$ to the local variable \texttt{x},
and this example compiles without warnings. Typed Lua allows
programmers to combine annotated code with
unannotated code, as we show in the following example:
\begin{verbatim}
    local function abs(n: number)
      if n < 0 then
        return -n
      else
        return n
      end
    end

    local function distance(x, y)
      return abs(x - y)
    end
\end{verbatim}

The compiler assigns the dynamic type $\Any$ to the input
parameters of \texttt{distance} because they do not have type annotations.
Subtracting a value of type $\Any$ from another also yields a value of
type $\Any$ (Lua has operator overloading, so the minus operation
is not guaranteed to return a number in this case), but
consistent subtyping lets us pass a value of type $\Any$ to a
function that expects a $\Number$. 

Even though the return types
of both {\tt abs} and {\tt distance} are not given, the compiler is able to
infer a return type of $\Number$ to both functions, as they are
local and not recursive.

Lua has first-class functions, but they have some peculiarities. First,
the number of arguments passed to a function does not need to
match the function's arity; Lua silently drops extra arguments after
evaluating them, or passes {\tt nil} in place of any missing arguments.
Second, functions can return any number of values, and the number
of values returned may not be statically known. Third, Lua also has
multiple assignment, and the semantics of argument passing match
those of multiple assignment (or vice-versa); calling a function is like
doing a multiple assigment where the left side is the parameter list
and the right side is the argument list. 

Typed Lua uses {\em second-class types} to encode the peculiarities
of argument passing, multiple returns, and multiple assignment. We call
them second-class because these types do not correspond to actual
values and cannot be assigned to variables or parameters: they are an
artifact of the interaction between the type system and the semantics of Lua.

As we saw in Figure \ref{fig:typelang}, a second-class type in
Typed Lua can be the type $\Void$ (the empty tuple),
a tuple of first-class types optionally ending in a variadic type,
or a union of these tuples. A variadic type $T*$ is a generator for a
sequence of values of type $T \cup \Nil$. Unions of tuples play
an important part in functions that are overloaded on the return type,
together with {\em projection types}. Both are explained in the next
section.

Typed Lua always adds a
variadic tail to the parts of a function type if none is specified, to match
the semantics of Lua function calls. In the examples above, the types
of {\tt factorial} and {\tt abs} are actually $\Number \times \Top *
 \rightarrow \Number \times \Nil *$, and the type of {\tt distance} is
$\Any \times \Any \times \Top * \rightarrow \Number \times \Nil *$.

If we call {\tt abs} with extra arguments, Typed Lua silently ignores
them, as the type signature lets {\tt abs} receive any number of extra
arguments. If we call {\tt abs} in the right side of an assignment to
more than one lvalue, Typed Lua checks if the first lvalue has a type
consistent with $\Number$, and any other lvalues need to have a type
consistent with $\Nil$.

A variadic type can only appear in the tail position of a tuple,
because Lua takes only the first value of any expression that appears
in an expression list that is not in tail position. The following example
shows the interaction between multiple returns and expression lists:

\begin{verbatim}
    local function multiple()
      return 2, "foo"
    end

    local function sum(x: number, y: number)
      return x + y
    end

    local x, y, z = multiple(), multiple()
    print(sum(multiple(), multiple())
\end{verbatim}

Function {\tt multiple} is
$\Top * \rightarrow \Number \times \String \times \Nil *$,
and {\tt sum} is $\Number \times \Number \times \Top * \rightarrow
\Number \times \Nil *$. In the right side of the multiple assignment,
only the first value produced by the first call to multiple gets used, so
the type of the right side is $\Number \times \Number \times \String \times \Nil*$,
and the types assigned to {\tt x}, {\tt y}, and {\tt z} are respectively $\Number$,
$\Number$, and $\String$. This also means that the call to {\tt sum} compiles
without errors, as the first two components of the tuple are consistent with
the types of the parameters, and the other components are consistent with
$\Top$.

\section{Unions}
\label{sec:unions}

Typed Lua uses union types to encode some common Lua idioms:
optional values, overloading based on the tags of input parameters,
and overloading on the return type of the functions.

Optional values are unions of some type and $\Nil$, and are so
common that Typed Lua uses the {\tt t?} syntax for these unions.
They appear any time a function has optional parameters, and
any time the program reads a value from an array or map.

\begin{verbatim}
    local function message(name: string,
                           greeting: string?)
      local greeting = greeting or "Hello "
      return greeting .. name
    end
    
    print(message("Lua"))
    print(message("Lua", "Hi"))
\end{verbatim}

In this example, the second parameter is optional but, in the first
line of the function, we declare a new variable that is guaranteed to
have type $\String$ instead of $\String \cup \Nil$. In Lua, any value
except {\tt nil} and {\tt false} are "truthy", so the short-circuiting
{\tt or} operator is a common way of giving a default value to an
optional parameter. Typed Lua encodes this idiom with a typing rule: if
the left side of {\tt or} has type $T \cup Nil$ and the right side
has type $T$ then the {\tt or} expression has type $T$.

Declaring a new {\tt greeting} variable that shadows the parameter
is not necessary:

\begin{verbatim}
    local function message(name: string, 
                           greeting: string?)
      greeting = greeting or "Hello "
      return greeting .. name
    end
\end{verbatim}

Typed Lua lets assignment change the type of a local variable in
cases that respect a simple heuristic: the new type must be a
subtype of the previous one, and the variable must be local
to the current function. The new type only applies for the
remainder of the current scope.

Overloaded functions use the {\tt type} function to inspect
the tag of their parameters, and perform different actions
depending on what those tags are. The simplest case overloads
on just a single parameter:

\begin{verbatim}
    local function overload(s1: string, 
                            s2: string|number)
      if type(s2) == "string" then
        return s1 .. s2
      else
        -- string.rep: (string, number) -> string
        return string.rep(s1, s2)
      end
    end
\end{verbatim}

Typed Lua has a small set of type predicates that, when used
over a local variable in a condition, constrain the type of that
variable. The function above uses the {\tt type(X) == "string"}
predicate which constrains the type of $X$ from $T \cup \String$ to
$\String$ when the predicate is true and $T$ otherwise. This is
a simplified form of {\em flow typing}~\cite{guha:flow}.

The type predicates can only discriminate based on tags, so they
are limited on the kinds of unions that they can discriminate. It
is possible to discriminate a union that combines a table type with
a base type, or a table type with a function type, or a two base types,
but it is not possible to discriminate between two different function
types.

Functions that overload their return types to signal the ocurrence
of errors are another common Lua idiom. In this idiom, a function
returns its normal set of return values in case of success but,
if anything fails, returns {\tt nil} as the first value, followed
by an error message or other data describing the error, as in the
following example:

\begin{verbatim}
    local function idiv(d1: number, d2: number):
          (number, number)|(nil, string)
      if d2 == 0 then
        return nil, "division by zero"
      else
        local r = d1 % d2
        local q = (d1 - r)/d2
        return q, r
      end
    end
\end{verbatim}

There is also special syntax for this idiom: we could
annotate the return type of {\tt idiv} with {\tt (number, number)?}
to denote the same union\footnote{The parentheses are always
necessary here: {\tt number?} is {\tt number|nil}, while {\tt (number)}
is {\tt (number)|(nil, string)}.}. 

The full type of {\tt idiv} is $\Number \times \Number \times
\Top * \rightarrow (\Number \times \Number \times \Nil *) \cup
(\Nil \times \String \times \Nil *)$. A typical client of this
function would use it as follows:

\begin{verbatim}
    local q, r = idiv(n1, n2)
    -- q is number|nil, r is number|string
    if q then
      -- q and r are numbers
    else
      -- r is a string
    end
\end{verbatim}

When Typed Lua encounters a union of tuples in the right side
of an declaration, it stores the the union in a special type
environment with a fresh name and assigns {\em projection types} 
to the variables in the left side of the declaration. If the type
variable is $X$, variable {\tt q} gets type $X_1$ and variable
{\tt r} gets type $X_2$.

If we need to check a projection type
against some other type, we take the union of the corresponding
component in each tuple. But if we a variable with a projection
type appears in a type predicate, the predicate discriminates
against all tuples in the union. In the example above,
$X$ is $(\Number \times \Number \times \Nil *) \cup
(\Nil \times \String \times \Nil *)$ outside of the {\tt if}
statement, but $\Number \times \Number \times \Nil *$ in the
{\tt then} block and $\Nil \times \String \times \Nil *$ in
the {\tt else} block.

Notice that we could also discriminate using {\tt r}, using
{\tt type(r) == "number"} as our predicate, with the same
result. The first form is more succint, and more idiomatic.
We can also use projection types to write overloaded functions
where the type of a parameter depends on the type of another
parameter.

Assigning to a variable with a projection type is forbidden,
unless the union has been discriminated down to a single tuple,
Unrestricted assignment to these variables would be unsound,
as it could break the dependency relation between the types
in each tuple that is part of the union.

Currently, a limitation of our overloading mechanisms is that
the return type cannot depend on the input types; we cannot
write a function that is guaranteed to return a number if
passed a number and guaranteed to return a string if passed
a string, for example.

\section{Tables and Interfaces}
\label{sec:tables}

Tables are the main mechanism that Lua has to build data
structures. They are associative arrays where any value
(except {\tt nil}) can be a key, but with language support
for efficiently using tables as tuples, arrays (dense or sparse),
records, modules, and objects. In this section,
we show how Typed Lua encodes tables as arrays, records, tuples,
and plain maps in its type system.

Typed Lua uses the same framework to represent the different
uses that a Lua table has: {\em table types}. A table type
$\{ t_{1}:u_{1}, \ldots, t_{n}:u_{n}\}$ represents a map
from values of type $t_i$ to values of type $u_i$.

The concrete syntax of Typed Lua has syntax for
common table types. One syntax defines table types for
maps: it is written \texttt{\{ t: u \}},
and maps to the table type $\{t:u\}$.
This table type represents a map that maps values of type
$t$ to values of type $u \cup \Nil$.
Another syntax defines table types for arrays:
it is written \texttt{\{ t \}}, and maps to the table type
$\{\Number:t\}$. A third syntax sugar defines
table types for records:
it is written \texttt{\{ s1: t1, ..., sn: tn \}}, where
each $s_i$ is a literal number, string, or boolean, 
and maps to the table type $\{s_{1}:t_{1}, ..., s_{n}:t_{n}\}$,
where each $s_i$ is the corresponding literal type.

The example below shows how we can define a map from
strings to numbers; the dot syntax for field access
in Lua is actually syntactic sugar for indexing a table
with a string literal:

\begin{verbatim}
    local t: { string: number } = { foo = 1 }
    local x: number = t.foo         -- x gets 1
    local y: number = t["bar"]      -- runtime error
\end{verbatim}

When accessing a map, there is always the possibility that
the key is not there. In Lua, accessing a non-existing key
returns {\tt nil}. Typed Lua is stricter, and raises a runtime
error in this case. To get a map with the behavior of standard
Lua tables, the programmer can use an union:

\begin{verbatim}
    local t: { string: number? } = { foo = 1 }
    local x: number = t.foo         -- error
    local y: number = t.bar or 0    -- y gets 0
    local z: number? = t["bar"]     -- z gets nil
\end{verbatim}

Now the Typed Lua compiler will complain about the assignment
on line two. The following example shows how we can declare
an array:
\begin{verbatim}
    local days: { string } = { "Sunday", "Monday",
      "Tuesday", "Wednesday", "Thursday",
      "Friday", "Saturday" }
    local x = days[1]          -- x gets "Sunday"
    local y = days[8]          -- runtime error
\end{verbatim}

Notice that we have the same strictness with missing
elements, unless the type of the elements has {\tt nil}
as a possible value.

If we want to declare a tuple, we can leave the
variable declaration unannotated and let Typed Lua assign
a more specific table type to the variable.
If we remove the annotation in the previous example, 
the compiler assigns the following table type to \texttt{days}:
\begin{align*}
\{{1:\String},\;{2:\String},\;{3:\String},\;{4:\String},\;\\
{5:\String},\;{6:\String},\;{7:\String}\}
\end{align*}

This type is not a subtype of $\{\Number:\String\}$, nor
is $\{\Number:\String\}$ a subtype of $\{\Number:
\String\cup\Nil\}$, because in both cases the subtype
relationship would be unsound. In the first case,
a table type with the same fields as the type above,
plus $8: \Number$, is a subtype of the table type
above, so would also be a subtype of $\{\Number:\String\}$,
which is clearly unsound. In the second case, covariance
in the type of mutable fields is also unsound, for the
same reason as the unsoundness of array covariance.

While the record type above, $\{\Number:\String\}$, and
$\{\Number: \String\cup\Nil\}$ are disjoint, all three
types are valid for the table constructed in the example.
Typed Lua actually assigns different types to a table constructor
expression depending on the context where it is used.

Finally, the next example shows how we can declare a record:

\begin{verbatim}
    local person: { "firstname": string,
                    "lastname": string } =
      { firstname = "Lou", lastname = "Reed" } 
\end{verbatim}

We could leave the type annotation out, and Typed Lua would
assign the same type to {\tt person}.

As records get bigger, and types of record fields get more
complicated, writing table types can be unwieldy, so Typed
Lua has {\em interfaces} as syntactic sugar for record types:

\begin{verbatim}
    local interface Person
      firstname: string
      lastname: string
    end
\end{verbatim}

The declaration above declares {\tt Person} as an alias to
the record type $\{$``firstname": $\String$,
 ``lastname": $\String\}$ in
the remainder of the current scope. We can now use {\tt Person} in
type declarations:

\begin{verbatim}
    local function greet(person: Person)
      return "Hello, " .. person.firstname ..
             " " .. person.lastname
    end

    local user1 = { firstname = "Lewis",
                    middlename = "Allan",
                    lastname = "Reed" }
    local user2 = { firstname = "Lou" }
    local user3 = { lastname = "Reed",
                    firstname = "Lou" }
    local user4 = { "Lou", "Reed" }

    print(greeter(user1)) -- Hello, Lewis Reed
    print(greeter(user2)) -- Error
    print(greeter(user3)) -- Hello, Lou Reed
    print(greeter(user4)) -- Error
\end{verbatim}

If our record type has fields that can be {\tt nil}, we need
to use an explicit type declaration when declaring a
variable of this record type, as the following example shows:

\begin{verbatim}
    local interface Person
      firstname: string
      middlename: string?
      lastname: string
    end

    local user1: Person = { firstname = "Lewis",
                            middlename = "Allan",
                            lastname = "Reed" }
    local user2: Person = { lastname = "Reed",
                            firstname = "Lou" }
\end{verbatim}

We need an explicit type declaration because neither of
the types that the Typed Lua compiler assigns to the
table constructors above is a subtype of $\{$``firstname":
$\String$, ``middlename": $\String \cup \Nil$, ``lastname":
$\String\}$, the type that {\tt Person} describes.

We can also use interfaces to define recursive types:

\begin{verbatim}
    local interface Element
      info: number
      next: Element?
    end
\end{verbatim}

It is common in Lua programs to build a record incrementally,
starting with an empty table, as in the following example:

\begin{verbatim}
    local person = {}
    person.firstname = "Lou"
    person.lastname = "Reed"
\end{verbatim}

Ideally, we want the type of {\tt person} to change as the
table gets built, from $\{\}$ to $\{$``firstname": $\String\}$
and finally to $\{$``firstname": $\String$, ``lastname":
 $\String\}$. This is tricker than the type change introduced
by assignment that we saw in Section 2.2, as what is changing
is not just the type of the variable {\tt person} but the
type of the value that {\tt person} points to. This is safe
in the example above, but not in the example below:

\begin{verbatim}
    local bogus = { firstname = 1 }
    local person: {} = bogus
    person.firstname = "Lou"
    person.lastname = "Reed"
\end{verbatim}

The assignment on line two is perfectly legal, as the type
of {\tt bogus} is a subtype of $\{\}$. But changing the type
of {\tt person} would be unsound: {\tt person.firstname} is
now a $\String$, but {\tt bogus.firstname} is still typed
as a $\Number$. We do not even need to declare a type for
aliasing to be a problem: 

\begin{verbatim}
    local person = {}
    local bogus = person
    bogus.firstname = 1
    person.firstname = "Lou"
    person.lastname = "Reed"
\end{verbatim}

Taken individually, the changes to the type of the two
variables look ok, but aliasing makes one of them unsound.
The location of the change also matters, as the next example
shows:

\begin{verbatim}
    local person = {}
    local bogus = { firstname = 1 }
    do
      person.firstname = 1
      bogus = person
    end
    do
      person.firstname = "Lou"
    end
    -- bogus.firstname is now "Lou"
\end{verbatim}

The initial type of {\tt person} in all of these examples is
$\{\}$, but the {\em origin} of this type judgment matters
on whether it is sound to allow a change to the type of
{\tt person} or not, even if the change is always towards
a subtype of the current type.

Typed Lua tags a variable with a table type as either
{\em open} or {\em closed}. If a variable gets its type
from a table constructor then it is open, otherwise it is
always closed. The type of an open variable may change
by field assignment, subject to two restrictions: the
variable must be local to the current block, and the new type
must be a subtype of the old type.

Using a variable with an open type can also trigger a
type change, if the type of the missing fields has
{\tt nil} as a possible value. This lets the programmer
incrementally create an instance of an interface with
an optional type:

\begin{verbatim}
    local interface Person
      firstname: string
      middlename: string?
      lastname: string
    end

    local user = {}
    user.firstname = "Lou"
    user.lastname = "Reed"
    local person: Person = user
\end{verbatim}

Table types are the foundation for modules and objects in
Typed Lua. Type changes triggered by field assignment are
also an important part of Typed Lua's support for the
idiomatic definition of Lua modules, which are the
subject of the next section.

\section{Modules}
\label{sec:modules}

Lua's module system, like other parts of the language, is
a matter of convention. When Lua first needs to load a
module, it executes the module's source file as a function;
the value that this function returns is the module, and Lua
caches it for future loads. While a module can be any
Lua value, most modules are tables where the fields
of the table are functions and other values that the
module exports.

The modules that we surveyed build this table using
three distinct styles. In the first style, the module's
source file ends
with a {\tt return} statement that uses a table constructor
with the exported members. In the second style, the
module declares an empty table in the beginning of its
source file, adds exported members to this table
throughout the module, and returns this table at the end.

These two styles are straightforward for Typed Lua, which
can just take the type of the first value that the module
returns and use it as the type of the module.

In the third style, which has been deprecated in the current
version of Lua, a module begins with a call to the {\tt module}
function. This function installs a fresh table as the
global environment for the rest of the module, so any
assignments to global variables are field assignments to
this table. The {\tt module} function also sets an {\tt \_M}
field in this table as a circular reference to the table
itself, so the module can end with {\tt return \_M}, but
this explicit return is not necessary.

While this style has been deprecated, our survey indicated
that around a third of Lua modules in a popular module
repository still use this style, so Typed Lua also
supports this style: it treats accesses to global
variables as field accesses to an open table
in the top-level scope.

\section{Objects and Classes}
\label{sec:classes}

Lua's built-in support for object oriented programming is
minimal. The basic mechanism is the {\tt :} syntactic
sugar for method calls and method declarations.
The Lua compiler translates {\tt obj:method(args)}
to an operation that evaluates {\tt obj}, looks
for a field named ``method" in the result, then calls
it with the result of evaluating {\tt obj} as the
first argument, followed by the result of evaluating
the argument list in the original expression.

Besides interfaces, Typed Lua will also introduce classes.
We want to offer classes as a standard way for writing code that
Lua programmers are already using, but without tying them to a
specific model.
Our classes will not include static attributes and will also not offer
privacy rules.


\section{Related Work}
 \label{sec:review}

We begin this section presenting a little bit of the history about
combining static and dynamic typing in the same language.
After that, we introduce optional type systems and gradual typing.
We end this section discussing why optional type systems and two
other approaches are often called gradual typing.

\subsection{A little bit of history}

Common LISP \citep{steele1982ocl} introduced optional type annotations
in the early eighties, but not for static type checking.
Instead, programmers may choose to declare types of variables as
optimization hints to the compiler, that is, type declarations are
just one way to help the compiler to optimize code.
These annotations are unsafe because they can crash the program
when they are wrong.

\citet{abadi1989dts} extended the simply typed lambda calculus with the
\texttt{Dynamic} type and the \texttt{dynamic} and \texttt{typecase}
constructs, with the aim to safely integrate dynamic code in
statically typed languages.
The \texttt{Dynamic} type is a pair \texttt{(v,T)} where \texttt{v} is a
value and \texttt{T} is the tag that represents the type of \texttt{v}.
The constructs \texttt{dynamic} and \texttt{typecase} are explicit
injection and projection operations, respectively.
That is, \texttt{dynamic} builds values of type \texttt{Dynamic} and
\texttt{typecase} safely inspects the type of a \texttt{Dynamic} value.
Thus, migrating code between dynamic and static type checking requires
changing type annotations and adding or removing \texttt{dynamic} and
\texttt{typecase} constructs throughout the code.

The \textit{quasi-static} type system proposed by \citet{thatte1990qst}
performs implicit coercions and run-time checks to replace the
\texttt{dynamic} and \texttt{typecase} constructs that were proposed by
\citet{abadi1989dts}.
To do that, quasi-static typing relies on subtyping with a top type
$\Omega$ that represents the dynamic type, and splits type checking
into two phases.
The first phase inserts implicit coercions from the dynamic type to
the expected type, while the second phase performs what Thatte calls
\textit{plausibility checking}, that is, it rewrites the program to
guarantee that sequences of upcasts and downcasts always have a
common subtype.

\textit{Soft typing} \citep{cartwright1991soft} is another approach
to combine static and dynamic typing in the same language.
The main goal of soft typing is to add static type checking to
dynamically typed languages without compromising their flexibility.
To do that, soft typing relies on type inference for
translating dynamically typed code to statically typed code.
The type checker inserts run-time checks around inconsistent code and
warns the programmer about the insertion of these run-time checks,
as they mean the existence of potential type errors.
However, the programmer is free to choose between inspecting the
run-time checks and simply running the code.
Soft typing gives this choice to the programmer because it is one of
its key ideas, that is, type inference and static type checking should
not prevent the programmer from running inconsistent code.
One advantage of soft typing is the fact that the compiler for
softly typed languages can use the translated code to generate
more efficient code, as the translated code statically type checks.
One disadvantage of soft typing is that it can be cumbersome when
the inferred types are meaningless large types that just confuse the
programmer.

\textit{Dynamic typing} \citep{henglein1994dts} is an approach
that optimizes code from dynamically typed languages by eliminating
unnecessary checks of tags.
The paper describes how to translate dynamically typed code to
statically typed code that uses a \texttt{Dynamic} type.
The translation is done through a coercion calculus that uses type
inference to insert the operations that are necessary to type check
the \texttt{Dynamic} type during run-time.
Although soft typing and dynamic typing may seem similar, they are not.
They are not similar because soft typing targets statically type
checking of dynamically typed languages for detecting programming
errors while dynamic typing targets the optimization of dynamically
typed code through the elimination of unnecessary run-time checks.
In other words, soft typing sees code optimization as a side effect
that comes with static type checking.

\citet{findler2002chf} proposed contracts for higher-order functions
and blame annotations for run-time checks.
Contracts perform dynamic checking instead of static checking,
but deferring all verifications to run-time can lead to defects
that are difficult to fix, because run-time errors can show a
stack trace where it is not clear to programmers if the cause of a
certain run-time error is in application code or library code.
Even if programmers identify that the source of a certain run-time
error is in library code, they still may have problems to identify
if this run-time error is due to a violation of library's contract,
or due to a bug, when the library is poorly documented.
In this approach, programmers can insert assertions in the form of
contracts that check the input and output of higher-order functions.
Thus, \citet{findler2002chf} show how programmers can insert
assertions in the form of contracts that check the input and output
of higher-order functions; and they also show how to add blame
annotations in the generated code as a way to track assertion
failures back to the source of the error.

BabyJ \citep{anderson2002babyj} is an object-oriented language
without inheritance that allows programmers to incrementally annotate
the code with more specific types.
Programmers can choose between using the dynamically typed version
of BabyJ, when they do not need types at all, and the statically
typed version of BabyJ, when they need to annotate the code.
In the statically typed BabyJ, programmers can use the
\textit{permissive type} $*$ to annotate the parts of the code that
still do not have a specific type or the parts of the code that should
have dynamic behavior.
The type system of BabyJ is nominal, so types are either class names
or the permissive type $*$.
However, the type system does not use type equality or subtyping,
but the relation $\approx$ between two types.
The relation $\approx$ holds when both types have the same name or
any of them is the permissive type $*$.
Even though the permissive type $*$ is similar to the dynamic type
from previous approaches, BabyJ does not provide any way to add
implicit or explicit run-time checks.

\citet{ou2004dtd} specified a language that combines static types
with dependent types.
To ensure safety, the compiler automatically inserts coercions
between dependent code and static code.
The coercions are run-time checks that ensure static code does not
crash dependent code during run-time.

\subsection{Optional Type Systems}

Optional type systems \citep{bracha2004pluggable} are an approach for
plugging static typing in dynamically typed languages through
optional type annotations that are used to perform compile-time type
checking, though not influencing the original run-time semantics of
the language.
This means that optional type systems can be unsound without affecting
language safety, because the run-time semantics should still catch
type errors independently of the static type checking.
More precisely, optional type systems are unsound if they do not catch
some type errors, but we say that languages with unsound optional type
systems are safe because the semantics of these languages catch during
run-time the type errors that the optional type system did not catch.
Although optional type systems maintain the simplicity and
flexibility of dynamically typed languages, their static type
checking cannot prove the absence of all type errors when the optional
type system is unsound.

Optional type systems have an interesting relation to the untyped
lambda calculus and the typed lambda calculus.
The semantic rules of the unytped lambda calculus are the same of the
typed lambda calculus, and the type system is actually optional and
serves only for discarding programs that may have undesired behaviors
\citep{bracha2004pluggable}.

Optional type systems make software evolution easier and
allow language designers to experiment with
\textit{pluggable type systems} \citep{bracha2004pluggable}.
Pluggable type systems are different optional type systems for
checking different aspects of the program.

According to \citet{bracha2004pluggable}, optional type systems should
not include mandatory type inference too, because mandatory type
inference may decrease the expressiveness of the type system.
Instead, optional type systems should implement type inference as
an independent mechanism that can be turned on and off according to
the programmers' needs.

Unfortunately, there is no formalization on optional type systems,
so each language ends up implementing its optional type system on
its own way.
Now we will briefly discuss some languages that provide an informal
description of their optional type systems rather than a formal one.

Strongtalk \citep{bracha1993strongtalk,bracha1996strongtalk} is
a version of Smalltalk that comes with an optional type system that
does not include any type inference.

Dart \citep{dart} and TypeScript \citep{typescript} are new
languages that are designed with an optional type system, and both
use JavaScript as their code generation target because their main
purpose is web development.
In fact, Dart is a new class-based object-oriented language with
optional type annotations while TypeScript is a strict superset of
JavaScript that provides optional type annotations and class-based
object-oriented programming.
Both Dart and TypeScript perform type inference to deduce static
types for unannotated code.

\subsection{Gradual Typing}

The main goal of gradual typing \citep{siek2006gradual} is to allow
programmers to choose between static and dynamic typing in the same
language.
To do that, \citet{siek2006gradual} extended the simply typed
lambda calculus with the dynamic type $?$.
In gradual typing, type annotations are optional, so an untyped
variable is syntactic sugar for a variable whose declared type is
the dynamic type $?$.
Under these circumstances, we view gradual typing as a way to add
a dynamic type to statically typed languages.

The central idea of gradual typing is the \textit{consistency}
relation, written $\tau_{1} \sim \tau_{2}$, that allows implicit
conversions to and from the dynamic type, and disallows conversions
between inconsistent types \citep{siek2006gradual}.
For instance, $\mathbf{int} \sim \,?$ and $?\, \sim \mathbf{int}$,
but $\mathbf{int} \not\sim \mathbf{string}$ and
$\mathbf{string} \not\sim \mathbf{int}$. 
The consistency relation is neither commutative nor transitive.

Gradual typing is similar to the approaches proposed by
\citet{abadi1989dts} and \citet{thatte1990qst} by including a
dynamic type to a statically typed language.
However, these three approaches differ in the way they handle the
dynamic type.
While \citet{siek2006gradual} rely on the consistency relation,
\citet{abadi1989dts} rely on type equality with explicit projections
and injections, and \citet{thatte1990qst} relies on subtyping.
The subtyping relation actually is a pitfall on Thatte's quasi-static
typing, because the dynamic type is put as the top and the bottom of
the subtyping relation.
Therefore, downcasts combined with the transitivity of subtyping
accepts programs that should be rejected.

Later, \citet{siek2007objects} discovered that the consistency relation
is orthogonal to subtyping, so we can combine the two relations to
achieve both consistency and subtyping.
The \textit{consistent-subtyping} relation,
written $\tau_{1} \lesssim \tau_{2}$,
is essential to design object-oriented languages that have a
gradual type system.
Like the consistency relation, and unlike the subtyping relation,
the consistent-subtyping relation is not transitive.

Another important feature of gradual typing is the theoretic
foundation that it provides for inserting run-time checks that
prove dynamically typed code does not violate the invariants of
statically typed code, thus preserving type safety.
To do that, \citet{siek2006gradual} defined the run-time semantics
of gradual typing as a translation to an intermediate language with
explicit casts at the frontiers between statically and dynamically
typed code.
The semantics of these casts is based on the higher-order contracts
proposed by \citet{findler2002chf}.

However, \citet{herman2007sgt} showed that there is an efficiency
concern regarding the run-time checks, because there are two
ways that casts can lead to unbounded space consumption.
The first affects tail recursion while the second appears when
first-class functions or objects cross the border between
static code and dynamic code, that is, some programs can apply
repeated casts to the same function or object.
\citet{herman2007sgt} use the coercion calculus of
\citet{henglein1994dts} to solve the problem of space efficiency,
that is, they use coercions to express casts.
Their approach normalizes an arbitrary sequence of coercions to a
coercion of bounded size.

Another concern about casts is how to improve debugging support,
because a cast application can be delayed and the error related
to that cast application can appear far way from the real error.
\citet{wadler2009wpc} developed the \textit{blame calculus} as a way
to attack this issue, and \citet{ahmed2011bfa} extended the
blame calculus with polymorphism.
The blame calculus is an intermediate language to integrate
static and dynamic typing that uses the blame tracking approach
proposed by \citet{findler2002chf}.

On the one hand, the blame calculus solves the issue regarding
error reporting;
on the other hand, it has the space efficiency problem reported
by \citet{herman2007sgt}.
Thus, \citet{siek2009casts} extended the coercion calculus of
\citet{herman2007sgt} with blame tracking to achieve an
implementation of the blame calculus that is space efficient.
After that, \citet{siek2010blame} proposed a new solution that also
attacks both problems.
This new solution is based on a concept called \textit{threesome},
which is a way to split a cast between two parties into two casts
among three parties.
A cast has a source and a target type (a \textit{twosome}),
so we can split any cast into a downcast from the source to an
intermediate type that is followed by an upcast from the intermediate
type to the target type (a \textit{threesome}).

ActionScript \citep{moock2007as3} is the first language that
incorporated a gradual type system to its implementation and
Perl 6 \citep{tang2007pri} is also being designed with a
gradual type system, though there is little documentation about
the gradual type systems of these languages.
Grace \citep{black2012grace,black2013sg} is a new object-oriented,
gradually typed, educational language.
In Grace, modules are gradually typed objects, that is, modules
may have types and methods as attributes, and can have a state
\citep{homer2013modules}.
Gradual Python \citep{reticulated} is an attempt to develop a
gradual type system for Python that deals with mutable objects
\citep{siek2013mutable}.
Gradualtalk \citep{allende2013gts} is a gradually-typed Smalltalk
that introduces a new cast insertion strategy for gradually-typed
objects \citep{allende2013cis}.

\subsection{Approaches that are often called Gradual Typing}

Gradual typing is similar to optional type systems in that type
annotations are optional, and unannotated code is dynamically
typed, but unlike optional type systems, gradual typing changes 
the run-time semantics to preserve type safety, and it is a way to
add a dynamic type to statically typed languages. 
More precisely, programming languages that include a gradual type
system implement the semantics of statically typed languages, so
the gradual type system inserts casts in the translated code to
guarantee that types are consistent before execution, while
programming languages that include an optional type system still
implement the semantics of dynamically typed languages, so all
the type checking also belongs to the semantics of each operation.

Still, we can view gradual typing as a way to formalize an optional
type system when the gradual type system does not insert run-time
checks.
BabyJ \citep{anderson2002babyj} and Alore \citep{lehtosalo2011alore}
are two examples of object-oriented languages that use gradual
typing to formalize their optional type systems.
The optional type systems of both BabyJ and Alore are nominal.
BabyJ uses the relation $\approx$ that is similar to the consistency
relation while Alore combines  subtyping along with the consistency
relation to define a \textit{consistent-or-subtype} relation.
The consistent-or-subtype relation is different from the
consistent-subtyping relation of \citet{siek2007objects}, but it is
also written $\tau_{1} \lesssim \tau_{2}$.
The consistent-or-subtype relation holds when $\tau_{1} \sim \tau_{2}$
or $\tau_{1} <: \tau_{2}$, so $<:$ is transitive and $\sim$ is not.
Alore also extends its optional type system to include optional
monitoring of run-time type errors in the gradual typing style.

Hence, optional type annotations for software evolution probably are
the reasons why optional type systems are commonly called
gradual type systems.
Typed Clojure \citep{bonnaire-sergeant2012typed-clojure} is an
optional type system for Clojure that now is adopting the
gradual typing slogan.

\citet{flanagan2006htc} introduced \textit{hybrid type checking},
an approach that combines static types and refinement types.
For instance, programmers can specify the refinement type
$\{x:Int \;|\; x \ge 0\}$ when they need a type for natural numbers.
The programmer can also choose between explicit or implicit casts.
When casts are not explicit, the type checker uses a theorem prover
to insert casts.
In our example of natural numbers, a cast would be inserted to check
whether an integer is greater than or equal to zero.

Sage \citep{gronski2006sage} is a programming language that
extended hybrid type checking with a dynamic type to
support dynamic and static typing in the same language.
Sage also offers optional type annotations in the gradual typing
style, that is, unannotated code is syntactic sugar for
code whose declared type is the dynamic type.

Thus, the inclusion of a dynamic type to hybrid type checking
along with optional type annotations, and the insertion of run-time
checks probably are the reasons why hybrid type checking is
also viewed as a form of gradual typing. 

\citet{tobin-hochstadt2006ims} proposed another approach for gradually
migrating from dynamically typed to statically typed code,
and they coined the term \textit{from scripts to programs} for
referring to this kind of interlanguage migration.
In their approach, the migration from dynamically typed to
statically typed code happens module-by-module, so they designed
and implemented Typed Racket \citep{tobin-hochstadt2008ts} for
this purpose.
Typed Racket is a statically typed version of Racket
(a Scheme dialect) that allows the programmer to write typed modules,
so Typed Racket modules can coexist with Racket modules,
which are untyped.

The approach used by \citet{tobin-hochstadt2008ts} to design and
implement Typed Racket probably is also called gradual typing
because it allows the programmer to gradually migrate from untyped
scripts to typed programs.
However, note that Typed Racket is a statically typed language
and type annotations are mandatory.
So, what makes it gradual is a type system with a dynamic type
that handles the interaction between Racket and Typed Racket modules.

\subsection{Similar Lua projects}

Metalua \citep{metalua} is a Lua compiler that supports compile-time
metaprogramming (CTMP).
CTMP is a kind of macro system that allows the programmers to interact
with the compiler \citep{fleutot2007contrasting}. 
Metalua extends Lua 5.1 syntax to include its macro system,
and allows programmers to define their own syntax.
Metalua can provide syntactical support for several object-oriented
styles, and can also provide syntax for turning simple type
annotations into run-time assertions.

MoonScript \citep{moonscript} is a programming language that supports
class-based object-oriented programming, and compiles to idiomatic
Lua code.
However, it does not perform compile-time type checking.

LuaInspect \citep{luainspect} is a tool that uses MetaLua to perform
some code analysis, such as flagging unknown global variables and
table fields, checking the number of function arguments against
signatures, and inferring function return values, but it does not
try to analyze object-oriented code and does not perform compile-time
type checking.

Tidal Lock \citep{tidallock} is a prototype of another optional type
system for Lua, which is written in Metalua.
A remarkable feature of Tidal Lock is the way that it handles tables,
because it allows the programmer to incrementally build the type of
a table.
More precisely, Tidal Lock allows the programmer to create an empty
table to build its type according to the keys that the programmer
inserts in it, so the programmer does not need to build the table in
a single table constructor.
Typed Lua has a simpler form of this feature, with a different
formalization.
Like Typed Lua, Tidal Lock also has local type inference.
Unlike Typed Lua, Tidal Lock is not typing the common object-oriented
idioms used by Lua programmers.

\section{Conclusion} \label{sec:con}

\bibliographystyle{abbrvnat}
\bibliography{typedlua}

\end{document}
