
In the previous chapter we presented an informal overview of Typed Lua.
We showed that programmers can use Typed Lua to combine static and dynamic
typing in the same code, and it allows them to incrementally migrate from
dynamic to static typing.
This is a benefit to programmers that use dynamically typed languages
to build large applications, as static types detect many bugs
during the development phase, and also provide better documentation.

In this chapter we present the formalization of Typed Lua's type system.
Besides its practical contributions, Typed Lua also has some interesting
contributions to the field of optional type systems for scripting
languages.
They are novel type system features that let Typed Lua cover several Lua idioms
and features, such as refinement of tables, multiple return values,
and optional parameters.

\section{Types}
\label{sec:types}

\begin{figure}[!ht]
\textbf{Type Language}\\
\dstart
$$
\begin{array}{rlr}
t ::= & & \textsc{first-level types:}\\
& \;\; l & \textit{literal types}\\
& | \; b & \textit{base types}\\
& | \; \Nil & \textit{nil type}\\
& | \; \Value & \textit{top type}\\
& | \; \Any & \textit{dynamic type}\\
& | \; \Self & \textit{self type}\\
& | \; t \cup t & \textit{disjoint union types}\\
& | \; s \rightarrow s & \textit{function types}\\
& | \; \{k_{1}{:}v_{1}, ..., k_{n}{:}v_{n}\}_{unique|open|closed|regular} & \textit{table types}\\
& | \; x & \textit{type variables}\\
& | \; \mu x.t & \textit{recursive types}\\
& | \; \phi(t,t) & \textit{filter types}\\
& | \; \pi_{i}^{x} & \textit{projection types}\\
%\multicolumn{3}{c}{}\\
l ::= & & \textsc{{\small literal types:}}\\
& \;\; \False \; | \; \True \; | \; {\it int} \; | \; {\it float} \; | \; {\it string} &\\
%\multicolumn{3}{c}{}\\
b ::= & & \textsc{{\small base types:}}\\
& \;\; \Boolean \; | \; \Integer \; | \; \Number \; | \; \String &\\
%\multicolumn{3}{c}{}\\
k ::= & & \textsc{{\small key types:}}\\
& \;\; l \; | \; b \; | \; \Value &\\
%\multicolumn{3}{c}{}\\
v ::= & & \textsc{{\small value types:}}\\
& \;\; t \; | \; \Const \; t &\\ 
%\multicolumn{3}{c}{}\\
s ::= & & \textsc{second-level types:}\\
& \;\; p & \textit{tuple types}\\
& | \; s \sqcup s & \textit{unions of tuple types}\\
%\multicolumn{3}{c}{}\\
p ::= & & \textsc{{\small tuple types:}}\\
& \;\; \Void & \textit{void type}\\
& | \; t* & \textit{variadic types}\\
& | \; t \times p & \textit{pair types}
\end{array}
$$
\dend
\caption{The abstract syntax of Typed Lua types}
\label{fig:typelang}
\end{figure}

Figure \ref{fig:typelang} presents the abstract syntax of
Typed Lua types.
Typed Lua splits types into two categories:
\emph{first-level types} and \emph{second-level types}.
First-level types represent first-class Lua values and
second-level types represent tuples of values that appear in 
assignments and function applications.
First-level types include literal types, base types, the type $\Nil$,
the top type $\Value$, the dynamic type $\Any$, the type $\Self$,
union types, function types, table types, recursive types,
filter types, and projection types.
Second-level types include tuple types and unions of tuple types.
Tuple types include the type $\Void$, variadic types, and pair types.
Types are ordered by a subtype relationship that we introduce
in Section \ref{sec:subtyping}, so Lua values may belong to
several distinct types.

Literal types represent the type of literal values.
They can be the boolean values $\False$ and $\True$,
an integer value, a floating point value, or a string value.
We will see that literal types are important in our treatment of
table types as records.

Typed Lua includes four base types: $\Boolean$, $\Integer$, $\Number$, and $\String$.
The base types $\Boolean$ and $\String$ represent the values that
Lua tags as \texttt{boolean} and \texttt{string} during run-time.
Lua 5.3 introduced two internal representations to the tag \texttt{number}:
\texttt{integer} for integer numbers and \texttt{float} for real numbers.
Lua does automatic promotion of \texttt{integer} values to \texttt{float}
values as needed.
We introduced the base type $\Number$ to represent \texttt{float} values,
and the base type $\Integer$ to represent \texttt{integer} values.
In the next section we will show that $\Integer$ is a subtype of $\Number$.
This allows programmers to keep using \texttt{integer} values where
\texttt{float} values are expected.

The type $\Nil$ is the type of \texttt{nil}, the value that Lua uses for
undefined variables, missing parameters, and missing table keys.

The type $\Value$ is the top type, which represents any Lua value.
In Section \ref{sec:rules} we will show that this type,
along with variadic types, helps the type system to drop extra values
on assignments and function calls, thus preserving the
semantics of Lua in these cases.

Typed Lua uses the type $\Self$ to represent the \emph{receiver}
in object-oriented method definitions and method calls.
As we mentioned in Section \ref{sec:oop}, we need the type
$\Self$ to prevent programs from indexing a method without
calling it with the correct receiver.

Union types $t_{1} \cup t_{2}$ represent types that can hold a value
of two different types.

Function types have the form $s \rightarrow s$ and represent Lua functions,
where $s$ is a second-level type.

Second-level types are either tuple types or unions of tuple types.
Tuple types are tuples of first-level types that can end with
either an empty tuple or with a variadic type.
Typed Lua needs second-level types because tuples are not first-class
values in Lua, only appearing on argument passing, multiple returns,
and multiple assignments.
The type $\Void$ is the type of an empty tuple.
A variadic type $t*$ represents a sequence of values of type $t \cup \Nil$;
it is the type of a vararg expression.
Second-level types include unions of tuples because Lua programs
usually overload the return type of functions to denote error,
as we mentioned in Section \ref{sec:statistics}.
For clarity, we use the symbol $\sqcup$ to represent the union between
two different tuple types.
Note that $\cup$ represents the union between two first-level types,
while $\sqcup$ represents the union between two tuple types.

Back to first-level types, table types represent the various forms
that Lua tables can take.
The syntactical form of table types is $\{ k_{1}{:}v_{1}, ..., k_{n}{:}v_{n} \}_{tag}$,
where each $k_{i}$ represents the type of a table key,
and each $v_{i}$ represents the type of the value that table keys of type $k_{i}$ map to.
Key types can only be literal types, base types, or the top type.
We made this restriction to the type of the keys because the statistics
that we discussed in Section \ref{sec:statistics} showed that most
of the tables are records, lists, and hashes.
The type $\Value$ is an option when we need a loose table type.
For instance, $\{\Value:\Value\}_{regular}$ represents the type of a
table in which both indices and values can have any type.
Value types can be any first-level type, and can optionally include
the $\Const$ type to denote immutable values.

We also use the tags \emph{unique}, \emph{open}, \emph{closed}, and
\emph{regular} to classify table types.
The tag \emph{unique} represents tables with no keys that do not
inhabit one of the table's key types, and with no alias.
In particular, the type of the table constructor has this tag.
The tag \emph{open} represents \emph{unique} table types that
have at least one alias.
The tag \emph{closed} represents \emph{unique} table types
that may have aliases.
In particular, the type of a class has this tag.
The tag \emph{regular} represents table types that do not provide
any guarantees about keys with types not listed in the table type.
In particular, in the concrete syntax, type annotations, interface
declarations, and userdata declarations always describe \emph{regular} table types.
In the next sections we explain in more detail why we need
different table types.

Any table type has to be \emph{well-formed}.
Informally, a table type is well-formed if key types do not overlap.
In Section \ref{sec:rules} we formalize the definition of well-formed table types.
We delay the proper formalization of well-formed table types because we use
consistent-subtyping in this formalization.

Recursive types have the form $\mu x.t$,
where $t$ is a first-level type that $x$ represents.
For instance, $\mu x.\{``info":\Integer, ``next":x \;\cup\; \Nil\}_{regular}$
is a type for singly-linked lists of integers.
In Section \ref{sec:alias} we mentioned that we can use the following
interface declaration as an alias to this type:
\begin{verbatim}
    local interface Element
      info:integer
      next:Element?
    end
\end{verbatim}

Typed Lua includes filter types as a way to discriminate the type of local
variables inside conditions.
In Section \ref{sec:rules} we show in more detail how our type system
uses them to formalize the \texttt{type} predicates that we mentioned
in Section \ref{sec:unions}.

Typed Lua includes projection types as a way to project
unions of tuple types into unions of first-level types.
In Section \ref{sec:rules} we show in more detail how our type system
uses them as a mechanism for handling unions of tuple types,
when they appear on the right-hand side of the declaration of local variables,
as we mentioned in Section \ref{sec:unions}.
We also show how this feature allows our type system to constrain
the type of a local variable that depends on the type of another local variable.

Typed Lua includes the dynamic type $\Any$ for allowing programmers
to mix static and dynamic typing.

\section{Subtyping}
\label{sec:subtyping}

Our type system uses subtyping \citep{cardelli1984smi,abadi1996to} to order
types and consistent-subtyping \citep{siek2007objects,siek2013mutable}
to allow the interaction between statically and dynamically typed code.
We explain the subtyping and consistent-subtyping rules throughout this section.
However, we focus the discussion on the definition of subtyping because,
as we mentioned in Section \ref{sec:gradual}, we can combine the
consistency and subtyping relations to achieve consistent-subtyping.
The differences between subtyping and consistent-subtyping are the way
they handle the dynamic type, and the fact that subtyping is transitive,
but consistent-subtyping is not.

We present the subtyping rules as a deduction system for the
subtyping relation $\senv \vdash t_{1} \subtype t_{2}$.
The variable $\senv$ is a set of pairs of recursion variables.
We need this set to record the hypotheses that we assume when checking
recursive types.

The subtyping rules for literal types and base types include the rules
for defining that literal types are subtypes of their respective base types,
and that $\Integer$ is subtype of $\Number$:
\[
\begin{array}{c}
\begin{array}{c}
\mylabel{S-FALSE}\\
\senv \vdash \False \subtype \Boolean
\end{array}
\;
\begin{array}{c}
\mylabel{S-TRUE}\\
\senv \vdash \True \subtype \Boolean
\end{array}
\;
\begin{array}{c}
\mylabel{S-STRING}\\
\senv \vdash {\it string} \subtype \String
\end{array}
\\ \\
\begin{array}{c}
\mylabel{S-INT1}\\
\senv \vdash {\it int} \subtype \Integer
\end{array}
\;
\begin{array}{c}
\mylabel{S-INT2}\\
\senv \vdash {\it int} \subtype \Number
\end{array}
\;
\begin{array}{c}
\mylabel{S-FLOAT}\\
\senv \vdash {\it float} \subtype \Number
\end{array}
\\ \\
\begin{array}{c}
\mylabel{S-NUMBER}\\
\senv \vdash \Integer \subtype \Number
\end{array}
\end{array}
\]

Subtyping is reflexive and transitive;
therefore, we could have omitted the rule \textsc{S-INT2}.
More precisely, we could have defined a transitive rule for first-level
types instead of defining specific rules for transitive cases.
For instance, a transitive rule would allow us to derive that
\[
\dfrac{\senv \vdash 1 \subtype \Integer \;\;\;
       \senv \vdash \Integer \subtype \Number}
      {\senv \vdash 1 \subtype \Number}
\]

However, we are using the subtyping rules as the template for defining
the consistent-subtyping rules, and consistent-subtyping is not
transitive.
More precisely, we want the subtyping and consistent-subtyping rules
to differ only in the way they handle the dynamic type.
Thus, we define the subtyping rules using an algorithmic approach
that is close to the implementation, as this approach allows us to use
subtyping to easily formalize consistent-subtyping.

Our type system includes the top type $\Value$,
so any first-level type is a subtype of $\Value$:
\[
\begin{array}{c}
\mylabel{S-VALUE}\\
\senv \vdash t \subtype \Value
\end{array}
\]

Many programming languages include a bottom type to represent
an empty value that programmers can use as a default expression,
and we could have used the type $\Nil$ for this role.
However, making $\Nil$ the bottom type would lead to several expressions
that would pass the type checker, but that would fail during run-time
in the presence of a \texttt{nil} value.
Thus, our type system does not have a bottom type, and $\Nil$ is a
subtype only of itself and of $\Value$.

Another type that is only a subtype of itself and of the type $\Value$
is the type $\Self$.

The subtyping rules for union types are standard:
\[
\begin{array}{c}
\begin{array}{c}
\mylabel{S-UNION1}\\
\dfrac{\senv \vdash t_{1} \subtype t \;\;\;
       \senv \vdash t_{2} \subtype t}
      {\senv \vdash t_{1} \cup t_{2} \subtype t}
\end{array}
\;
\begin{array}{c}
\mylabel{S-UNION2}\\
\dfrac{\senv \vdash t \subtype t_{1}}
      {\senv \vdash t \subtype t_{1} \cup t_{2}}
\end{array}
\;
\begin{array}{c}
\mylabel{S-UNION3}\\
\dfrac{\senv \vdash t \subtype t_{2}}
      {\senv \vdash t \subtype t_{1} \cup t_{2}}
\end{array}
\end{array}
\]

The first rule shows that a union type $t_{1} \cup t_{2}$
is subtype of $t$ if both $t_{1}$ and $t_{2}$ are subtypes
of $t$;
and the other rules show that a type $t$ is subtype
of a union type $t_{1} \cup t_{2}$ if $t$ is subtype of
either $t_{1}$ or $t_{2}$.

The subtyping rule for function types is also standard:
\[
\begin{array}{c}
\mylabel{S-FUNCTION}\\
\dfrac{\senv \vdash s_{2} \subtype s_{1} \;\;\;
       \senv \vdash r_{1} \subtype r_{2}}
      {\senv \vdash s_{1} \rightarrow s_{1} \subtype s_{2} \rightarrow r_{2}}
\end{array}
\]

The rule \textsc{S-FUNCTION} shows that subtyping between
function types is contravariant on the type of the parameter list
and covariant on the return type.
In the previous section we explained why our type system uses
second-level types to represent the type of the parameter list
and the return type.
Now, we explain their subtyping rules.

The type $\Void$ is a subtype of itself and of a variadic type:
\[
\begin{array}{c}
\mylabel{S-VOID}\\
\senv \vdash \Void \subtype t{*}
\end{array}
\]

A variadic type $t{*}$ represents a sequence of values of type
$t \cup \Nil$, and the rule \textsc{S-VOID} handles the case where
a given sequence is empty.

The subtyping rule for pair types is the standard covariant rule:
\[
\begin{array}{c}
\mylabel{S-PAIR}\\
\dfrac{\senv \vdash t_{1} \subtype t_{2} \;\;\;
       \senv \vdash s_{1} \subtype s_{2}}
      {\senv \vdash t_{1} \times s_{1} \subtype t_{2} \times s_{2}}
\end{array}
\]

The subtyping rules for variadic types are not so obvious:
\[
\begin{array}{c}
\begin{array}{c}
\mylabel{S-VARARG1}\\
\senv \vdash \Nil{*} \subtype \Void
\end{array}
\\ \\
\begin{array}{c}
\mylabel{S-VARARG2}\\
\dfrac{\senv \vdash t_{1} \cup \Nil \subtype t_{2} \cup \Nil}
      {\senv \vdash t_{1}{*} \subtype t_{2}{*}}
\end{array}
\;
\begin{array}{c}
\mylabel{S-VARARG3}\\
\dfrac{\senv \vdash t_{1} \cup \Nil \subtype t_{2}}
      {\senv \vdash t_{1}{*} \subtype t_{2} \times \Void}
\end{array}
\;
\begin{array}{c}
\mylabel{S-VARARG4}\\
\dfrac{\senv \vdash t_{1} \subtype t_{2} \cup \Nil}
      {\senv \vdash t_{1} \times \Void \subtype t_{2}{*}}
\end{array}
\\ \\
\begin{array}{c}
\mylabel{S-VARARG5}\\
\dfrac{\senv \vdash t_{1}{*} \subtype t_{2} \times \Void \;\;\;
       \senv \vdash t_{1}{*} \subtype s_{2}}
      {\senv \vdash t_{1}{*} \subtype t_{2} \times s_{2}}
\end{array}
\;
\begin{array}{c}
\mylabel{S-VARARG6}\\
\dfrac{\senv \vdash t_{1} \times \Void \subtype t_{2}{*} \;\;\;
       \senv \vdash s_{1} \subtype t_{2}{*}}
      {\senv \vdash t_{1} \times s_{1} \subtype t_{2}{*}}
\end{array}
\end{array}
\]

We need six different subtyping rules for variadic types
to handle all the cases where they can appear.
The rule \textsc{S-VARARG1} is a special rule for handling the
case where we give a sequence of $\Nil$ to the empty tuple.
The rule \textsc{S-VARARG2} handles the case where both tuple types end
with variadic types, and shows that $t_{1}{*}$ is a subtype of $t_{2}{*}$
if $t_{1} \cup \Nil$ is a subtype of $t_{2} \cup \Nil$.
This rule explicitly includes $\Nil$ in both sides because otherwise
$\Nil{*}$ would not be a subtype of several other variadic types.
For instance, $\Nil{*}$ would not be subtype of $\Number{*}$,
as $\Nil \not\subtype \Number$.
The other rules handle the cases where only one tuple type ends with a variadic type.
Note that the case where both tuple types end with the type $\Void$ does
not require any special rule.
In the next section we will show that we use these subtyping rules,
along with the types $\Value$ and $\Nil$, to make our type system reflect
the semantics of Lua on discarding extra parameters and
replacing missing parameters.

The subtyping rules for unions of tuple types are similar to the
subtyping rules for unions of first-level types:
\[
\begin{array}{c}
\begin{array}{c}
\mylabel{S-UNION4}\\
\dfrac{\senv \vdash s_{1} \subtype s \;\;\;
       \senv \vdash s_{2} \subtype s}
      {\senv \vdash s_{1} \sqcup s_{2} \subtype s}
\end{array}
\;
\begin{array}{c}
\mylabel{S-UNION5}\\
\dfrac{\senv \vdash s \subtype s_{1}}
      {\senv \vdash s \subtype s_{1} \sqcup s_{2}}
\end{array}
\;
\begin{array}{c}
\mylabel{S-UNION6}\\
\dfrac{\senv \vdash s \subtype s_{2}}
      {\senv \vdash s \subtype s_{1} \sqcup s_{2}}
\end{array}
\end{array}
\]

Back to the subtyping rules between first-level types,
the subtyping rule among a \emph{closed} or \emph{regular}
table type and another \emph{regular} table type resembles the
standard subtyping rule between records:
\[
\begin{array}{c}
\mylabel{S-TABLE1}\\
\dfrac{\forall i \in 1..n \; \exists j \in 1..m \;\;\;
       \senv \vdash k_{j} \subtype k_{i}' \;\;\;
       \senv \vdash k_{i}' \subtype k_{j} \;\;\;
       \senv \vdash v_{j} \subtype_{c} v_{i}'}
      {\senv \vdash \{k_{1}{:}v_{1}, ..., k_{m}{:}v_{m}\}_{closed|regular} \subtype \{k_{1}'{:}v_{1}', ..., k_{n}'{:}v_{n}'\}_{regular}} \; m \ge n
\end{array}
\]

The rule \textsc{S-TABLE1} allows width subtyping and introduces the
auxiliary relation $\subtype_{c}$ to handle depth subtyping on the
type of the values stored in the table fields.
We need an auxiliary relation because the subtyping of the
type of the values stored in the table fields changes according to
the tags of the table types.
We define the relation $\subtype_{c}$ as follows:
\[
\begin{array}{c}
\begin{array}{c}
\mylabel{S-FIELD1}\\
\dfrac{\senv \vdash v_{1} \subtype v_{2} \;\;\;
       \senv \vdash v_{2} \subtype v_{1}}
      {\senv \vdash v_{1} \subtype_{c} v_{2}}
\end{array}
\;
\begin{array}{c}
\mylabel{S-FIELD2}\\
\dfrac{\senv \vdash v_{1} \subtype v_{2}}
      {\senv \vdash \Const \; v_{1} \subtype_{c} \Const \; v_{2}}
\end{array}
\\ \\
\begin{array}{c}
\mylabel{S-FIELD3}\\
\dfrac{\senv \vdash v_{1} \subtype v_{2}}
      {\senv \vdash v_{1} \subtype_{c} \Const \; v_{2}}
\end{array}
\end{array}
\]

These rules allow depth subtyping on $\Const$ fields.
The rule \textsc{S-FIELD1} defines that mutable fields are invariant,
while the rule \textsc{S-FIELD2} defines that immutable fields are covariant.
The rule \textsc{S-FIELD3} defines that it is safe to promote fields
from mutable to immutable.
We do not include a rule that allows promoting fields from immutable
to mutable because this would be unsafe due to variance.

There is a limitation on \emph{regular} table types that led us to
introduce \emph{open} and \emph{unique} table types.
If the table constructor had a \emph{regular} table type, then
programmers would not be able to use it to initialize a variable with
a table type that describes a more general type.
For instance,
\begin{verbatim}
    local t:{"x":integer, "y":integer?} = { x = 1, y = 2 }
\end{verbatim}
would not type check, as the type of the table constructor would not
be a subtype of the type in the annotation.
More precisely,
\[
\{``x":1, ``y":2\}_{regular} \not\subtype \{``x":\Integer, ``y":\Integer \cup \Nil\}_{regular}
\]

Simply promoting the type of each table value to its supertype would
not overcome this limitation, as it still would give to the table constructor
a regular table type without covariant mutable fields.
Thus, programmers would not be able to use the table constructor to
initialize a variable with a table type that includes an optional field.
Using the previous example,
\begin{align*}
& \{``x":\Integer, ``y":\Integer\}_{regular} \not\subtype \\
& \{``x":\Integer, ``y":\Integer \cup \Nil\}_{regular}
\end{align*}

We introduced \emph{unique} table types to avoid this limitation,
as they represent the type of tables with no keys that do not
inhabit one of the table's key types, and with no alias.
In particular, this is the case of the table constructor.
The following subtyping rule defines the subtyping relation among
\emph{unique} table types and \emph{regular} table types:
\[
\begin{array}{c}
\mylabel{S-TABLE2}\\
\dfrac{\begin{array}{c}
       \forall i \in 1..m \; \forall j \in 1..n \;
       \senv \vdash k_{i} \subtype k_{j}' \to \senv \vdash v_{i} \subtype_{u} v_{j}' \\
       \forall j \in 1..n \; \not\exists i \in 1..m \;
       \senv \vdash k_{i} \subtype k_{j}' \to \senv \vdash \Nil \subtype_{o} v_{j}'
       \end{array}}
      {\senv \vdash \{k_{1}{:}v_{1}, ..., k_{m}{:}v_{m}\}_{unique} \subtype
                    \{k_{1}'{:}v_{1}', ..., k_{n}'{:}v_{n}'\}_{regular}}
\end{array}
\]

The rule \textsc{S-TABLE2} allows width subtyping and covariant keys.
It allows covariant keys because we also want to use \emph{unique}
table types as a way to join table fields that inhabit \emph{regular} table types.
For instance, we want to use the table constructor to initialize
a variable with a table type that describes a hash.

The rule \textsc{S-TABLE2} introduced the auxiliary relations
$\subtype_{u}$ and $\subtype_{o}$.
The first allows depth subtyping on all fields,
while the second allows the omission of optional fields.
We define them as follows:
\[
\begin{array}{c}
\begin{array}{c}
\mylabel{S-FIELD4}\\
\dfrac{\senv \vdash v_{1} \subtype v_{2}}
      {\senv \vdash v_{1} \subtype_{u} v_{2}}
\end{array}
\;
\begin{array}{c}
\mylabel{S-FIELD5}\\
\dfrac{\senv \vdash v_{1} \subtype v_{2}}
      {\senv \vdash \Const \; v_{1} \subtype_{u} \Const \; v_{2}}
\end{array}
\;
\begin{array}{c}
\mylabel{S-FIELD6}\\
\dfrac{\senv \vdash v_{1} \subtype v_{2}}
      {\senv \vdash v_{1} \subtype_{u} \Const \; v_{2}}
\end{array}
\\ \\
\begin{array}{c}
\mylabel{S-FIELD7}\\
\dfrac{\senv \vdash \Nil \subtype v}
      {\senv \vdash \Nil \subtype_{o} v}
\end{array}
\;
\begin{array}{c}
\mylabel{S-FIELD8}\\
\dfrac{\senv \vdash \Nil \subtype v}
      {\senv \vdash \Nil \subtype_{o} \Const \; v}
\end{array}
\end{array}
\]

Using \emph{unique} table types to represent the type of the table
constructor allows our type system to type check the previous example.
More precisely,
\[
\{``x":1, ``y":2\}_{unique} \subtype \{``x":\Integer, ``y":\Integer \cup \Nil\}_{regular}
\]

Even though we allow width subtyping between \emph{unique} and \emph{regular}
table types, we do not allow it among \emph{unique} and other table types
because it would violate our definition of these other table types:
\[
\begin{array}{c}
\mylabel{S-TABLE3}\\
\dfrac{\begin{array}{c}
       \forall i \in 1..m \\
       \exists j \in 1..n \;
       \senv \vdash k_{i} \subtype k_{j}' \land \senv \vdash v_{i} \subtype_{u} v_{j}' \\
       \forall j \in 1..n \; \not\exists i \in 1..m \;
       \senv \vdash k_{i} \subtype k_{j}' \to \senv \vdash \Nil \subtype_{o} v_{j}'
       \end{array}}
      {\senv \vdash \{k_{1}{:}v_{1}, ..., k_{m}{:}v_{m}\}_{unique} \subtype
                    \{k_{1}'{:}v_{1}', ..., k_{n}'{:}v_{n}'\}_{unique|open|closed}}
\end{array}
\]

The rule that handles subtyping between \emph{open} and \emph{regular} table
types allows width subtyping:
\[
\begin{array}{c}
\mylabel{S-TABLE4}\\
\dfrac{\begin{array}{c}
       \forall i \in 1..m \; \forall j \in 1..n \;
       \senv \vdash k_{i} \subtype k_{j}' \to \senv \vdash v_{i} \subtype_{c} v_{j}' \\
       \forall j \in 1..n \; \not\exists i \in 1..m \;
       \senv \vdash k_{i} \subtype k_{j}' \to \senv \vdash \Nil \subtype_{o} v_{j}'
       \end{array}}
      {\senv \vdash \{k_{1}{:}v_{1}, ..., k_{m}{:}v_{m}\}_{open} \subtype
                    \{k_{1}'{:}v_{1}', ..., k_{n}'{:}v_{n}'\}_{regular}}
\end{array}
\]

However, the rule that handles subtyping among \emph{open} and
\emph{open} or \emph{closed} table types does not allow width subtyping:
\[
\begin{array}{c}
\mylabel{S-TABLE5}\\
\dfrac{\begin{array}{c}
       \forall i \in 1..m \\
       \exists j \in 1..n \;
       \senv \vdash k_{i} \subtype k_{j}' \land \senv \vdash v_{i} \subtype_{c} v_{j}' \\
       \forall j \in 1..n \; \not\exists i \in 1..m \;
       \senv \vdash k_{i} \subtype k_{j}' \to \senv \vdash \Nil \subtype_{o} v_{j}'
       \end{array}}
      {\senv \vdash \{k_{1}{:}v_{1}, ..., k_{m}{:}v_{m}\}_{open} \subtype
                    \{k_{1}'{:}v_{1}', ..., k_{n}'{:}v_{n}'\}_{open|closed}}
\end{array}
\]

The rules \textsc{S-TABLE4} and \textsc{S-TABLE5} allow joining fields
plus omitting optional fields.
Both rules use $\subtype_{c}$ to allow depth subtyping on $\Const$ fields only.

We introduced \emph{closed} table types because we needed a safe way
to represent the type of classes along with single inheritance.
The rule that handles subtyping between \emph{closed} table types
does not allow width subtyping, joining fields, and omitting fields,
but it allows depth subtyping on $\Const$ fields:
\[
\begin{array}{c}
\mylabel{S-TABLE6}\\
\dfrac{\forall i \in 1..n \; \exists j \in 1..n \;\;\;
       \senv \vdash k_{j} \subtype k_{i}' \;\;\;
       \senv \vdash k_{i}' \subtype k_{j} \;\;\;
       \senv \vdash v_{j} \subtype_{c} v_{i}'}
      {\senv \vdash \{k_{1}{:}v_{1}, ..., k_{n}{:}v_{n}\}_{closed} \subtype \{k_{1}'{:}v_{1}', ..., k_{n}'{:}v_{n}'\}_{closed}}
\end{array}
\]

In the next section we will show in more detail how our type system
uses \emph{unique}, \emph{open}, and \emph{closed} table types to
handle the refinement of table types.

We use the \emph{Amber rule} \citep{cardelli1986amber} to define
subtyping between recursive types:
\[
\begin{array}{c}
\begin{array}{c}
\mylabel{S-AMBER}\\
\dfrac{\senv[x_{1} \subtype x_{2}] \vdash t_{1} \subtype t_{2}}
      {\senv \vdash \mu x_{1}.t_{1} \subtype \mu x_{2}.t_{2}}
\end{array}
\;
\begin{array}{c}
\mylabel{S-ASSUMPTION}\\
\dfrac{x_{1} \subtype x_{2} \in \senv}
      {\senv \vdash x_{1} \subtype x_{2}}
\end{array}
\end{array}
\]

The rule \textsc{S-AMBER} also uses the rule \textsc{S-ASSUMPTION}
to check whether $\mu x_{1}.t_{1} \subtype \mu x_{2}.t_{2}$.
Both rules use the set of assumptions $\senv$,
where each assumption is a pair of recursion variables.
The rule \textsc{S-AMBER} extends $\senv$ with the assumption
$x_{1} \subtype x_{2}$ to check whether $t_{1} \subtype t_{2}$.
The rule \textsc{S-ASSUMPTION} allows the rule \textsc{S-AMBER}
to check whether an assumption is valid.

A recursive type may appear inside a first-level type, and our
type system includes subtyping rules to handle subtyping between
recursive types and other first-level types:
\[
\begin{array}{c}
\begin{array}{c}
\mylabel{S-UNFOLDR}\\
\dfrac{\senv \vdash t_{1} \subtype [x \mapsto \mu x.t_{2}]t_{2}}
      {\senv \vdash t_{1} \subtype \mu x.t_{2}}
\end{array}
\;
\begin{array}{c}
\mylabel{S-UNFOLDL}\\
\dfrac{\senv \vdash [x \mapsto \mu x.t_{1}]t_{1} \subtype t_{2}}
      {\senv \vdash \mu x.t_{1} \subtype t_{2}}
\end{array}
\end{array}
\]

As an example, the rule \textsc{S-UNFOLDR} allows our type system to
type check the function \texttt{insert} from Section \ref{sec:alias}:
\begin{verbatim}
    local function insert (e:Element?, v:integer):Element
      return { info = v, next = e }
    end
\end{verbatim}
that is, the type checker uses the rule \textsc{S-UNFOLDR} to verify whether
the type of the table constructor is a subtype of \texttt{Element}:
\begin{align*}
\{ & ``info":\Integer, \\
   & ``next":\mu x.\{``info":\Integer, ``next":x \;\cup\; \Nil\}_{regular} \cup \Nil \}_{unique} \subtype \\
& \mu x.\{``info":\Integer, ``next":x \;\cup\; \Nil\}_{regular}
\end{align*}

Filter types are subtypes only of themselves and of $\Value$.
More precisely, a filter type $\phi(t_{1},t_{2})$ is a subtype of
the same filter type $\phi(t_{1},t_{2})$, which shares the same
types $t_{1}$ and $t_{2}$, and it is also a subtype of $\Value$.

Projection types are subtypes only of themselves and of $\Value$.
More precisely, a projection type $\pi_{i}^{x}$ is a subtype of the
same projection type $\pi_{i}^{x}$, which shares the same union of
tuples $x$ and the same index $i$, and it is also a subtype of $\Value$.

The dynamic type $\Any$ is neither the bottom nor the top type,
but a separate type that is subtype only of itself and of $\Value$.

Even though the dynamic type $\Any$ does not interact with subtyping,
it does interact with consistent-subtyping.
We present the consistent-subtyping rules as a deduction system for
the consistent-subtyping relation $\senv \vdash t_{1} \lesssim t_{2}$.
As in the subtyping relation, $\senv$ is also a set of pairs of
recursion variables.
We define the consistent-subtyping rules for the dynamic type $\Any$
as follows:
\[
\begin{array}{c}
\begin{array}{c}
\mylabel{C-ANY1}\\
\senv \vdash t \lesssim \Any
\end{array}
\;
\begin{array}{c}
\mylabel{C-ANY2}\\
\senv \vdash \Any \lesssim t
\end{array}
\end{array}
\]

If we had set the type $\Any$ as both bottom and top types of our
subtyping relation, then any type $t_{1}$ would be a subtype of
any other type $t_{2}$.
The consequence of this is that all programs would type check without errors.
This would happen due to the transitivity of subtyping, that is,
we would be able to down-cast any type $t_{1}$ to $\Any$ and then up-cast
$\Any$ to any other type $t_{2}$.
The rules \textsc{C-ANY1} and \textsc{C-ANY2} are the rules that
allow the dynamic type to interact with other first-level types,
and thus allow dynamically typed code to coexist with statically
typed code.
Because of these two rules, consistent-subtyping cannot be transitive.
These two rules are the only rules that differ between
subtyping and consistent-subtyping, if we implement the subtyping rules
as we do in this section.

In the implementation of Typed Lua we also use consistent-subtyping to
normalize and simplify union types, though we let union types free in
the formalization.
For instance, the union type \texttt{boolean|any} results in the
type \texttt{any}, because \texttt{boolean} is consistent-subtype
of \texttt{any}.
Another example is the union type \texttt{number|nil|1} that
results in the union type \texttt{number|nil}, because
\texttt{1} is consistent-subtype of \texttt{number}.

\section{Typing rules}
\label{sec:rules}

In this section we use a reduced core of Typed Lua to present the
most interesting rules of our type system.
This core limits control flow to if and while statements,
has explicit type annotations, and explicit scope for variables.
It also has explicit method declarations and explicit method calls
instead of treating them as syntactic sugar.
We use this reduced core because it simplifies the presentation
of our type system.
Appendix \ref{app:rules} presents the full set of typing rules.

\begin{figure}[!ht]
\textbf{Abstract Syntax}\\
\dstart
$$
\begin{array}{rl}
s ::= & \;\; \mathbf{skip} \; | \;
s_{1} \; ; \; s_{2} \; | \;
\vec{l} = el \; | \;
m \; | \;
\mathbf{while} \; e \; \mathbf{do} \; s \; | \;
\mathbf{if} \; e \; \mathbf{then} \; s_{1} \; \mathbf{else} \; s_{2}\\
& | \; \mathbf{local} \; \vec{n{:}t} = el \; \mathbf{in} \; s \; | \;
\mathbf{rec} \; n{:}t = f \; \mathbf{in} \; s \; | \;
\mathbf{return} \; el \; | \;
e(el)_{s} \; | \;
e{:}n(el)_{s}\\
e ::= & \;\; \mathbf{nil} \; | \;
c \; | \;
{...}_{e} \; | \;
n_{e} \; | \;
e_{1}[e_{2}] \; | \;
{<}t{>} \; n \; | \;
f \; | \;
\{ \} \; | \;
\{ \; \vec{p} \; \} \; | \;
\{ \; {...}_{m} \; \} \; | \;
\{ \; \vec{p},{...}_{m} \; \}\\
& | \; e_{1} + e_{2} \; | \;
e_{1} \; {..} \; e_{2} \; | \;
e_{1} == e_{2} \; | \;
e_{1} < e_{2} \; | \;
e_{1} \; \mathbf{and} \; e_{2} \; | \;
e_{1} \; \mathbf{or} \; e_{2} \\
& | \; \mathbf{not} \; e \; | \;
- e \; | \;
\# \; e \; | \;
e(el)_{e} \; | \;
e{:}n(el)_{e}\\
l ::= & \;\; n_{l} \; | \;
e_{1}[e_{2}] \; | \;
n[c] \; {<}t{>}\\
c ::= & \;\; \mathbf{false} \; | \;
\mathbf{true} \; | \;
{\it int} \; | \;
{\it float} \; | \;
{\it string}\\
p ::= & \;\; [e_{1}] = e_{2}\\
el ::= & \;\; \mathbf{nothing} \; | \;
\vec{e} \; | \;
me \; | \;
\vec{e}, me \; | \;
me^{x} \; | \;
\vec{e}, me^{x}\\
me ::= & \;\; e(el)_{m} \; | \;
e{:}n(el)_{m} \; | \;
{...}_{m}\\
m ::= & \;\; \mathbf{fun} \; n_{1}{:}n_{2} \; (){:}r \; fb \; | \;
\mathbf{fun} \; n_{1}{:}n_{2} \; ({...}{:}t){:}r \; fb\\
& | \; \mathbf{fun} \; n_{1}{:}n_{2} \; (\vec{n{:}t}){:}r \; fb \; | \;
\mathbf{fun} \; n_{1}{:}n_{2} \; (\vec{n{:}t},{...}{:}t){:}r \; fb\\
f ::= & \;\; \mathbf{fun} \; (){:}r \; fb \; | \;
\mathbf{fun} \; ({...}{:}t){:}r \; fb \; | \;
\mathbf{fun} \; (\vec{n{:}t}){:}r \; fb \; | \;
\mathbf{fun} \; (\vec{n{:}t},{...}{:}t){:}r \; fb\\
fb ::= & \;\; s \;;\; \mathbf{return} \; el\\
n ::= & \;\; {\it name}\\
\end{array}
$$
\dend
\caption{Typed Lua abstract syntax}
\label{fig:syntax}
\end{figure}

Figure \ref{fig:syntax} presents the abstract syntax of core Typed Lua.
It splits the syntactic categories as follows:
$s$ are statements, $e$ are expressions, $l$ are left-hand values,
$el$ are expression lists, $c$ are literal constants, $p$ are table fields,
$me$ are expressions with multiple results, $f$ are function declarations,
$m$ are method declarations, $n$ are variable names,
$t$ are first-level types, and $r$ are second-level types.
The notation $\vec{n{:}t}$ denotes the non-empty list
$n_{1}{:}t_{1}, ..., n_{n}{:}t_{n}$.

Our reduced core also splits function application, method application, and
the vararg expression (${...}$) into different syntactic categories.
It uses $e(el)_{s}$ to denote function applications that produce no value
because they appear as statements,
$e(el)_{e}$ to denote function applications that produce only one value,
even if the function application returns multiple values,
and $e(el)_{m}$ to denote function applications that produces as many values
as the function application returns.
It uses the same categories for method applications.
For vararg expressions, it only uses ${...}_{e}$ and ${...}_{m}$,
as the vararg expression cannot appear as a statement.

We also include two kinds of type coercions in our core language:
the left-hand value $n[c] \; {<}t{>}$ and the expression ${<}t{>} \;n$.
Both allow the refinement of table types.
We also split variable names into two categories to have safe aliasing
of tables in the presence of refinement.
We use $n_{e}$ when they appear as expressions and $n_{l}$ when they
appear as left-hand values.

We present the typing rules as a deduction system for the typing relations
$\env_{1}, \penv \vdash s, \env_{2}$ and $\env_{1}, \penv \vdash e : t, \env_{2}$.
We use the first one for typing statements and the second one for typing expressions.
The first relation means that given a type environment $\env_{1}$
and a projection environment $\penv$, typing a statement $s$ produces
a new type environment $\env_{2}$.
The second relation means that given a type environment $\env_{1}$
and a projection environment $\penv$, typing a expression $e$ has
type $t$ and produces a new type environment $\env_{2}$.
We need two typing relations because only expressions have types,
though expressions and statements can modify a type environment.

Even though we can assign only first-level types to variables,
our type system should be able to project unions of first-level types
from unions of second-level types.
Thus, we need two environments because $\env$ maps variables to first-level types,
while $\penv$ maps variables to second-level types.
We will show how our type system uses the environment $\penv$ for
handling projection types.
We use $\env_{1}[n \mapsto t]$ to extend the environment $\env_{1}$
with the variable $n$ that maps to type $t$.
We use $\penv[x \mapsto r]$ to extend the environment $\penv$ with
the variable $x$ that maps to the second-level type $r$.

\subsection{Assignment and function application}
\label{sec:assignment}

Lua has multiple assignment, and the rule \textsc{T-ASSIGNMENT} uses
tuple types along with consistent-subtyping to type check this Lua feature:
\[
\begin{array}{c}
\mylabel{T-ASSIGNMENT}\\
\begin{array}{c}
\dfrac{\env_{1}, \penv \vdash el:r_{1}, \env_{2} \;\;\;
       \env_{2}, \penv \vdash \vec{l}:r_{2}, \env_{3} \;\;\;
       r_{1} \lesssim r_{2}}
      {\env_{1}, \penv \vdash \vec{l} = el,\env_{3}}
\end{array}
\end{array}
\]

As an example,
\[
x, y = 1, ``foo"
\]
type checks because
$1 \times ``foo" \times \Nil{*} \lesssim \Integer \times \String \times \Value{*}$,
assuming that $x$ and $y$ are in the environment with
types $\Integer$ and $\String$, respectively.

Our type system uses the type $\Value{*}$ to drop extra values
and the type $\Nil{*}$ to replace missing values.
The rule that type checks left-hand values list introduces the type
$\Value{*}$ to let the right-hand side produce more values than
expected in the left-hand side.
The rules that type check expression list introduce the type
$\Nil{*}$ to let the right-hand side produce fewer values than
expected in the left-hand side.
Our type system includes $\Nil{*}$ in the type of an expression list only
if its type does not end in another variadic type $t{*}$.
In the previous example, the rules \textsc{T-LHSLIST} and \textsc{T-EXPLIST2}
are the rules that introduce these types.
We define the rule \textsc{T-LHSLIST} as follows:
\[
\begin{array}{c}
\mylabel{T-LHSLIST}\\
\dfrac{\env, \penv \vdash l_{i}:t_{i}, \env_{i} \;\;\;
       \env_{m} = merge(\env_{1}, ..., \env_{n}) \;\;\;
       n = |\;\vec{l}\;|}
      {\env, \penv \vdash \vec{l}:t_{1} \times ... \times t_{n} \times \Value{*}, \env_{m}}
\end{array}
\]

First, this rule uses the same environment $\env$ to type check each
left-hand side value $l_{i}$.
Then, it takes each type $t_{i}$ and builds the tuple type for
the assignment rule, placing $\Value{*}$ in the end.
Table refinement can change the type environment while typing each left-hand value.
Thus, we use a partial auxiliary function \emph{merge} to collect
all the changes in a new environment $\env_{m}$, if there are no conflicts.

The rule \textsc{T-EXPLIST2} is similar to \textsc{T-LHSLIST}:
\[
\begin{array}{c}
\mylabel{T-EXPLIST2}\\
\dfrac{\env, \penv \vdash e_{i}:t_{i}, \env_{i} \;\;\;
       \env_{m} = merge(\env_{1}, ..., \env_{n}) \;\;\;
       n = |\;\vec{e}\;|}
      {\env, \penv \vdash \vec{e}:t_{1} \times ... \times t_{n} \times \Nil{*}, \env_{m}}
\end{array}
\]

We use \textsc{T-EXPLIST2} only when the last expression in the list
can produce a single value.
Rules \textsc{T-EXPLIST3} and \textsc{T-EXPLIST4} handle the case where
an expression list is just an expression that may produce multiple values:
\[
\begin{array}{c}
\begin{array}{c}
\mylabel{T-EXPLIST3}\\
\dfrac{\env_{1}, \penv \vdash me:t_{1} \times ... \times t_{n} \times \Void, \env_{2}}
      {\env_{1}, \penv \vdash me:t_{1} \times ... \times t_{n} \times \Nil{*}, \env_{2}}
\end{array}
\;
\begin{array}{c}
\mylabel{T-EXPLIST4}\\
\dfrac{\env_{1}, \penv \vdash me:t_{1} \times ... \times t_{n}{*}, \env_{2}}
      {\env_{1}, \penv \vdash me:t_{1} \times ... \times t_{n}{*}, \env_{2}}
\end{array}
\end{array}
\]

As an example, these rules allow our type system to type check the following example:
\[
x, y, z = f()_{m}
\]

In this example, we are assuming that $x$, $y$, $z$, and $f$ are in
the environment with types $\Integer$, $\String$, $\String \cup \Nil$, and
either $\Void \rightarrow \Integer \times \String \times \Void$ or
$\Value{*} \rightarrow \Integer \times \String \times \Nil{*}$,
depending on whether the programmer is using strict function types.
Thus, the example type checks because
\[
\Integer \times \String \times \Nil{*} \lesssim \Integer \times \String \times \String \cup \Nil \times \Value{*}
\]

Conversely,
\[
x = f()_{m}
\]
type checks because
\[
\Integer \times \String \times \Nil{*} \lesssim \Integer \times \Value{*}
\]

Rules for function applications are similar to the rule for multiple assignment.
The rule \textsc{T-APPLY1} handles the case where function applications
are expressions that produce multiple values:
\[
\begin{array}{c}
\mylabel{T-APPLY1}\\
\dfrac{\env_{1}, \penv \vdash e:r_{1} \rightarrow r_{2}, \env_{2} \;\;\;
       \env_{2}, \penv \vdash el:r_{3}, \env_{3} \;\;\;
       r_{3} \lesssim r_{1}}
      {\env_{1}, \penv \vdash e(el)_{m}:r_{2}, \env_{3}}
\end{array}
\]

We also use the rule \textsc{T-APPLY1} as the base case for the rules
that handle the cases where function applications are either statements
or expressions that produce only one value:
\[
\begin{array}{c}
\begin{array}{c}
\mylabel{T-STMAPPLY1}\\
\dfrac{\env_{1}, \penv \vdash e(el)_{m}:r, \env_{2}}
      {\env_{1}, \penv \vdash e(el)_{s},\env_{2}}
\end{array}
\;
\begin{array}{c}
\mylabel{T-EXPAPPLY1}\\
\dfrac{\env_{1}, \penv \vdash e(el)_{m}:r, \env_{2}}
      {\env_{1}, \penv \vdash e(el)_{e}:first(r), \env_{2}}
\end{array}
\end{array}
\]

The rule \textsc{T-STMAPPLY1} discards the produced values,
while the rule \textsc{T-EXPAPPLY1} uses the auxiliary function
\emph{first} to ensure that only one value is produced.
We can define \emph{first} inductively as follows:
\begin{align*}
first(\Void) & = \Nil\\
first(t{*}) & = t \cup \Nil\\
first(t \times r) & = t\\
first(r_{1} \sqcup r_{2}) & = first(r_{1}) \cup first(r_{2})
\end{align*}

Assuming that $f$ is a local function in the environment, and that $f$ has type
$\String \times \Integer \cup \Nil \times \Integer \cup \Nil \times \Value{*} \rightarrow \Integer{*}$,
the function call
\[
f(``foo")_{m}
\]
type checks through the rule \textsc{T-APPLY1}, because
\[
``foo" \times \Nil{*} \lesssim \String \times \Integer \cup \Nil \times \Integer \cup \Nil \times \Value{*}
\]
and the function call
\[
f(``foo",1,2,3)_{m}
\]
also type checks through the rule \textsc{T-APPLY1}, because
\[
``foo" \times 1 \times 2 \times 3 \times \Nil{*} \lesssim \String \times \Integer \cup \Nil \times \Integer \cup \Nil \times \Value{*}
\]

Our type system also catches arity mismatch.
For instance, assuming that $f$ has type
$\String \times \Integer \cup \Nil \times \Integer \cup \Nil \times \Void \rightarrow \Integer{*}$,
the function call
\[
f(``foo")_{m}
\]
type checks through the rule \textsc{T-APPLY1}, because
\[
``foo" \times \Nil{*} \lesssim \String \times \Integer \cup \Nil \times \Integer \cup \Nil \times \Void
\]
but the function call
\[
f(``foo",1,2,3)_{m}
\]
does not type check through the rule \textsc{T-APPLY1}, because
\[
``foo" \times 1 \times 2 \times 3 \times \Nil{*} \not\lesssim \String \times \Integer \cup \Nil \times \Integer \cup \Nil \times \Void
\]

When our type system type checks an expression list,
it always includes $\Nil{*}$ in the end of the type of this expression list
if its type does not end in a variadic type.
This behavior preserves the semantics of Lua on replacing missing values,
and it is necessary when we omit optional parameters in a function call,
like the previous example showed.

Using $\Nil{*}$ in the end of the type of expression lists also allows
our type system to catch arity mismatch in function calls without optional parameters.
For instance, assuming that $f$ has type
$\Integer \times \Integer \times \Void \rightarrow \Integer \times \Void$,
the function call
\[
f(1)_{m}
\]
does not type check through the rule \textsc{T-APPLY1}, because
\[
1 \times \Nil{*} \not\lesssim \Integer \times \Integer \times \Void
\]
and the function call
\[
f(1,2,3)_{m}
\]
also does not type check through the rule \textsc{T-APPLY1}, because
\[
1 \times 2 \times 3 \times \Nil{*} \not\lesssim \Integer \times \Integer \times \Void
\]

\subsection{Tables and refinement}
\label{sec:refinement}

The simplest expression involving tables in the empty table constructor.
Its type checking rule is straightforward:
\[
\begin{array}{c}
\mylabel{T-CONSTRUCTOR1}\\
\env, \penv \vdash \{\}:\{\}_{unique}, \env
\end{array}
\]

Our abstract syntax reduces the more complex uses of the table
constructor into three forms: $\{\;\vec{p}\;\}$, $\{\;{...}_{m}\;\}$,
and $\{\;\vec{p},{...}_{m}\;\}$.
The first one uses a list of table fields $[e_{1}] = e_{2}$,
the second one uses just the vararg expression, and the third one uses both.
We did not include in the abstract syntax a table constructor
that uses a list of expressions, because we can express it using the first form.
For instance, we can use the table constructor
$\{ [1] = ``x", [2] = ``y", [3] = ``z" \}$ to express $\{ ``x", ``y", ``z" \}$.

The rule \textsc{T-CONSTRUCTOR2} type checks a table type of the first form:
\[
\begin{array}{c}
\mylabel{T-CONSTRUCTOR2}\\
\dfrac{\env_{i}, \penv \vdash p_{i}:(k_{i},v_{i}), \env_{i+1} \;\;\;
       n = |\;\vec{p}\;| \;\;\;
       t = \{k_{1}{:}v_{1}, ..., k_{n}{:}v_{n}\}_{unique} \;\;\;
       wf(t)}
      {\env_{1}, \penv \vdash \{\;\vec{p}\;\}:t, \env_{n+1}}
\end{array}
\]

First, the rule \textsc{T-CONSTRUCTOR2} uses the auxiliary relation
$\env_{1}, \penv \vdash p : (k,v), \env_{2}$ to type check each table
field $p_{i}$.
This auxiliary relation means that given a type environment $\env_{1}$
and a projection environment $\penv$, typing a table field $p$
produces the pair $(k,v)$ and a new type environment $\env_{2}$. 
In the pair $(k,v)$, $k$ is type key type, while $v$ is the value type.

Then, the rule \textsc{T-CONSTRUCTOR2} uses each pair $(k_{i},v_{i})$
to build the table type that express the type of the given constructor, and
uses the predicate \emph{wf} to check whether this table type is well-formed.
Formally, a table type is well-formed if it obeys the following rule:
\[
\forall i \not\exists j \; i \not= j \wedge k_{i} \lesssim k_{j}
\]

Well-formed table types avoid ambiguity.
For instance, this rule detects that the table type
$\{1:\Number, \Integer:\String, \Any:\Boolean\}$ is ambiguous,
because the type of the value stored by key $1$ can be
$\Number$, $\String$, or $\Boolean$, as $1 \lesssim 1$,
$1 \lesssim \Integer$, and $1 \lesssim \Any$.
Moreover, the type of the value stored by a key of type $\Integer$,
which is not the literal type $1$, can be $\Number$ or $\Boolean$,
as $\Integer \lesssim \Integer$, and $\Integer \lesssim \Any$.

The definition of the auxiliary relation that type checks table
fields would be straightforward if our table types allowed any
first-level type in the type of the keys.
The rules \textsc{T-FIELD1}, \textsc{T-FIELD2}, and \textsc{T-FIELD3}
check if the type of the key is a subtype of $\Boolean$, $\Number$,
or $\String$, respectively:
\[
\begin{array}{c}
\begin{array}{c}
\mylabel{T-FIELD1}\\
\dfrac{\env_{1}, \penv \vdash e_{1}:t_{1}, \env_{2} \;\;\;
       \env_{2}, \penv \vdash e_{2}:t_{2}, \env_{3} \;\;\;
       t_{1} \subtype \Boolean}
      {\env_{1}, \penv \vdash [e_{1}] = e_{2}: (t_{1},rt(t_{2})), \env_{3}}
\end{array}
\\ \\
\begin{array}{c}
\mylabel{T-FIELD2}\\
\dfrac{\env_{1}, \penv \vdash e_{1}:t_{1}, \env_{2} \;\;\;
       \env_{2}, \penv \vdash e_{2}:t_{2}, \env_{3} \;\;\;
       t_{1} \subtype \Number}
      {\env_{1}, \penv \vdash [e_{1}] = e_{2}: (t_{1},rt(t_{2})), \env_{3}}
\end{array}
\\ \\
\begin{array}{c}
\mylabel{T-FIELD3}\\
\dfrac{\env_{1}, \penv \vdash e_{1}:t_{1}, \env_{2} \;\;\;
       \env_{2}, \penv \vdash e_{2}:t_{2}, \env_{3} \;\;\;
       t_{1} \subtype \String}
      {\env_{1}, \penv \vdash [e_{1}] = e_{2}: (t_{1},rt(t_{2})), \env_{3}}
\end{array}
\end{array}
\]

These rules use the function \emph{rt} in the type of the value
because our type system allows only \emph{regular} table types to
appear in the type of the values.
The function \emph{rt} promotes all table types to \emph{regular}.
We made this restriction because our type system does not keep track
of aliases to table fields.
This means that allowing \emph{unique}, \emph{open}, and \emph{closed}
table types to appear in the type of the values would allow the creation
of unsafe aliases.

The rule \textsc{T-FIELD4} is a fallback for the previous rules:
\[
\begin{array}{c}
\mylabel{T-FIELD4}\\
\dfrac{\env_{1}, \penv \vdash e_{1}:t_{1}, \env_{2} \;\;\;
       \env_{2}, \penv \vdash e_{2}:t_{2}, \env_{3}}
      {\env_{1}, \penv \vdash [e_{1}] = e_{2}: (\Value,rt(t_{2})), \env_{3}}
\end{array}
\]

The rule \textsc{T-FIELD4} shows that our type system uses the type $\Value$
as the type of the key whenever a key has a type that is neither a
subtype of $\Boolean$, nor a subtype of $\Number$, nor a subtype of $\String$.

As an example, the table constructor $\{[``x"] = 1, [``y"] = \{[``z"] = 2\}\}$
has type $\{``x":1, ``y":\{``z":2\}_{regular}\}_{unique}$ through the rules
\textsc{T-FIELD3} and \textsc{T-CONSTRUCTOR2}.

Typed Lua handles arrays as hashes that map integers to some type $t$.
In Lua, programmers often use the vararg expression to initialize arrays.
The rules \textsc{T-CONSTRUCTOR3} and \textsc{T-CONSTRUCTOR4} define
the behavior of the vararg expression for this case:
\[
\begin{array}{c}
\begin{array}{c}
\mylabel{T-CONSTRUCTOR3}\\
\dfrac{\env({...}) = t}
      {\env, \penv \vdash \{{...}_{m}\}:\{\Integer{:}t \cup \Nil\}_{unique}, \env}
\end{array}
\\ \\
\begin{array}{c}
\mylabel{T-CONSTRUCTOR4}\\
\dfrac{\begin{array}{c}
       \env_{i}, \penv \vdash p_{i}:(k_{i},v_{i}), \env_{i+1} \;\;\;
       n = |\;\vec{p}\;| \;\;\;
       \env_{i+1}({...}) = t_{v}\\
       t = \{k_{1}{:}v_{1}, ..., k_{n}{:}v_{n}, \Integer{:}t_{v} \cup \Nil\}_{unique} \;\;\;
       wf(t)
       \end{array}}
      {\env_{1}, \penv \vdash \{\;\vec{p},\;{...}_{m}\;\}:t, \env_{n+1}}
\end{array}
\end{array}
\]

The rule \textsc{T-CONSTRUCTOR3} type checks the case where we use
only the vararg expression inside a table constructor to initialize
an array.
If we assume that $...$ is in the environment and has type $\String$,
the table constructor $\{{...}_{m}\}$ has type $\{\Integer:\String \cup \Nil\}_{unique}$
through the rule \textsc{T-CONSTRUCTOR3}.

The rule \textsc{T-CONSTRUCTOR4} type checks the case where we use
the table constructor as a record that includes an array part.
If we assume that $...$ is in the environment and has type $\String$,
the table constructor $\{[``x"] = ``foo", [``y"] = \mathbf{true}, {...}_{m}\}$
has type $\{``x":``foo", ``y":\mathbf{true}, \Integer:\String \cup \Nil\}_{unique}$
through the rule \textsc{T-CONSTRUCTOR4}.
As another example, the rule \textsc{T-CONSTRUCTOR4} does not type check
the table constructor $\{ [1] = ``foo", [10] = \mathbf{true}, {...}_{m} \}$,
because the keys $1$ and $10$ overlap the array part,
and the resulting table type is not well-formed.

After discussing the typing rules of the table constructor,
we start the discussion of the rules that define the most
unusual feature of our type system: the refinement of table types.
The first kind of refinement allows programmers to add new
fields to \emph{unique} or \emph{open} table types through
field assignment.
For instance, in Section \ref{sec:tables} we presented the
following example:
\begin{verbatim}
    local person = {}
    person.firstname = "Lou"
    person.lastname = "Reed"
\end{verbatim}

We translate this example to our reduced core as follows:
\begin{center}
\begin{tabular}{ll}
\multicolumn{2}{l}{$\mathbf{local} \; person:\{\}_{unique} = \{\} \; \mathbf{in}$}\\
& \multicolumn{1}{l}{$person[``firstname"] \; {<}\String{>} = ``Lou";$}\\
& \multicolumn{1}{l}{$person[``lastname"] \; {<}\String{>} = ``Reed"$}
\end{tabular}
\end{center}

In this example, we assign the type $\{\}_{unique}$ to the variable
$person$, then we refine its type to $\{``firstname":\String\}_{unique}$,
and then we refine its type to $\{``firstname":\String, ``lastname":\String\}_{unique}$.
Rule \textsc{T-REFINE} type checks this use of refinement:
\[
\begin{array}{c}
\mylabel{T-REFINE}\\
\dfrac{\begin{array}{c}
       \env_{1}(n) = \{ k_{1}{:}v_{1}, ..., k_{n}{:}v_{n} \}_{open|unique}\\
       \env_{1}, \penv \vdash c:k, \env_{2} \;\;\;
       \not \exists i \in 1..n \; k \lesssim k_{i} \;\;\;
       v = rt(t)
       \end{array}}
      {\env_{1}, \penv \vdash n[c] {<}t{>}:t, \env_{2}[n \mapsto \{ k_{1}{:}v_{1}, ..., k_{n}{:}v_{n}, k{:}v\}_{open|unique}]}
\end{array}
\]

We restricted the refinement of table types to include only literal
keys, because its purpose is to make it easier the construction of
table types that represent records.

We use the refinement of table types to handle the declaration of
new global variables.
In Lua, the assignment \texttt{v = v + 1} translates to
\texttt{\string_ENV["v"] = \string_ENV["v"] + 1} when \texttt{v}
is not a local variable, where \texttt{\string_ENV} is a table
that stores the global environment.
For this reason, Typed Lua treats accesses to global variables as field accesses
to an open table in the top-level scope.
For instance,
\[
\string_ENV[``x"] \; {<}\String{>} = ``foo" \;;\; \string_ENV[``y"] \; {<}\Integer{>} = 1
\]
uses field assignment to add fields $``x"$ and $``y"$ to $\string_ENV$.
In this example and in the next examples we assume that
$\string_ENV$ is in the environment and has type $\{\}_{open}$.
Therefore, after these field assignments $\string_ENV$ has type
$\{``x":\String, ``y":\Integer\}_{open}$.

We do not allow the refinement of table types to add a field if it is
already present in the table's type.
For instance,
\[
\string_ENV[``x"] \; {<}\String{>} = ``foo" \;;\; \string_ENV[``x"] \; {<}\Integer{>} = 1
\]
does not type check, as we are trying to add $``x"$ twice.

We also do not allow the refinement of table types to introduce
fields with table types that are not \emph{regular}.
For instance,
\begin{center}
\begin{tabular}{l}
$\string_ENV[``x"] \; {<}\{\}_{unique}{>} = \{\}$
\end{tabular}
\end{center}
refines the type of $\string_ENV$ from $\{\}_{open}$ to $\{``x":\{\}_{regular}\}_{open}$.
Currently, our type system can only track \emph{unique} and
\emph{open} table types that are bound to local variables.

We can also use multiple assignment to refine table types:
\[
\string_ENV[``x"] \; {<}\String{>}, \string_ENV[``y"] \; {<}\Integer{>} = ``foo", 1
\]

This example type checks because all the environment changes are consistent, and
$``foo" \times 1 \times \Nil{*} \lesssim \String \times \Integer \times \Value{*}$.
However, the next example does not type check because it tries to add
the same field to $\string_ENV$, but with different types:
\[
\string_ENV[``x"] \; {<}\String{>}, \string_ENV[``x"] \; {<}\Integer{>} = ``foo", 1
\]

Aliasing an \emph{unique} or an \emph{open} table type produces a
\emph{closed} table type, as defined by rule \textsc{T-IDREAD}:
\[
\begin{array}{c}
\mylabel{T-IDREAD}\\
\dfrac{\env(n) = t_{1} \;\;\; t_{2} = read(\penv, t_{1})}
      {\env, \penv \vdash n_{e}:close(t_{2}), \env[n \mapsto open(t_{1})]}
\end{array}
\]

In Section \ref{sec:fap} we will explain that \textsc{T-IDREAD} uses
the auxiliary function \emph{read} because it may be accessing an
identifier that is bound to a filter or projection type.
As we mentioned in Section \ref{sec:unions}, our type system includes
a small set of \texttt{type} predicates that allow programmers to
discriminate union types.
In Section \ref{sec:fap} we will also explain that our type system
uses filter and projection types in the definition of these predicates
to handle the discrimination of unions of first-level and second-level
types.

The following example does not type check, as aliasing $a$ produces
the type $\{``foo":\Integer\}_{closed}$ that is not a subtype of
$\{``foo":\Integer \cup \Nil\}_{regular}$, the type of $b$:
\begin{center}
\begin{tabular}{lll}
\multicolumn{3}{l}{$\mathbf{local} \; a:\{``foo":\Integer\}_{unique} = \{ [``foo"] = 5 \} \; \mathbf{in}$}\\
& \multicolumn{2}{l}{$\mathbf{local} \; b:\{``foo":\Integer \cup \Nil \}_{regular} = a \; \mathbf{in}$}\\
& & \multicolumn{1}{l}{$b[``foo"] = \mathbf{nil}$}
\end{tabular}
\end{center}

As another example,
\begin{center}
\begin{tabular}{lll}
\multicolumn{3}{l}{$\mathbf{local} \; a:\{\}_{unique} = \{\} \; \mathbf{in}$}\\
& \multicolumn{2}{l}{$\mathbf{local} \; b:\{\}_{open} = a \; \mathbf{in}$}\\
& & \multicolumn{1}{l}{$a[``x"] \; {<}\String{>} = ``foo";$}\\
& & \multicolumn{1}{l}{$b[``x"] \; {<}\Integer{>} = 1$}\\
\end{tabular}
\end{center}
does not type check, as aliasing $a$ produces the type $\{\}_{closed}$
that is not a subtype of $\{\}_{open}$, the type of $b$.
Our type system has this behavior to warn programmers about
potential unsafe behaviors after this kind of alias.
In this example, it is unsafe to add the field $``x"$ to $b$,
as it changes the value that is stored in the field $``x"$ of $a$.

Aliasing an \emph{unique} table type while keeping the original
reference \emph{unique} can be unsafe.
For this reason, the rule \textsc{T-IDREAD} changes the type of
the original reference from \emph{unique} to \emph{open}.

We also need to close \emph{unique} and \emph{open} tables that
appear in the left-hand side of assignments, as defined by
rule \textsc{T-IDWRITE}:
\[
\begin{array}{c}
\mylabel{T-IDWRITE}\\
\dfrac{\env(n) = t_{1} \;\;\; t_{2} = write(t_{1})}
      {\env, \penv \vdash n_{l}:close(t_{2}), \env[n \mapsto close(t_{2})]}
\end{array}
\]

In Section \ref{sec:fap} we will explain that \textsc{T-IDWRITE} uses
the auxiliary function \emph{write} because it may be accessing an
identifier that is bound to a filter or projection type.
As we mentioned in Section \ref{sec:unions}, assignments restore
discriminated union types to their original types, and
function \emph{write} also works in this purpose.

As an example,
\begin{center}
\begin{tabular}{lll}
\multicolumn{3}{l}{$\mathbf{local} \; a:\{\}_{unique} = \{\} \; \mathbf{in}$}\\
& \multicolumn{2}{l}{$\mathbf{local} \; b:\{\}_{open} = \{\} \; \mathbf{in}$}\\
& & \multicolumn{1}{l}{$b = a;$}\\
& & \multicolumn{1}{l}{$a[``x"] \; {<}\String{>} = ``foo";$}\\
& & \multicolumn{1}{l}{$b[``x"] \; {<}\Integer{>} = 1$}\\
\end{tabular}
\end{center}
does not type check because we cannot add the field $``x"$ to $b$,
as its type is \emph{closed}, and thus does not allow changing the
value that is stored in the field $``x"$ of $a$.

We also have different rules for type checking table indexing to avoid
changing table types in these operations, as they cannot create aliases:
\[
\begin{array}{c}
\begin{array}{c}
\mylabel{T-INDEX1}\\
\dfrac{\begin{array}{c}
       \env_{1}(n) = t \;\;\;
       read(\penv, t) = \{k_{1}{:}v_{1}, ..., k_{n}{:}v_{n}\}\\
       \env_{1}, \penv \vdash e_{2}:k, \env_{2} \;\;\;
       \exists i \in 1{..}n \; k \lesssim k_{i}
       \end{array}}
      {\env_{1}, \penv \vdash n[e_{2}]:v_{i}, \env_{2}}
\end{array}
\\ \\
\begin{array}{c}
\mylabel{T-INDEX2}\\
\dfrac{\begin{array}{c}
       \env_{1}, \penv \vdash e_{1}:\{k_{1}{:}v_{1}, ..., k_{n}{:}v_{n}\}, \env_{2}\\
       \env_{2}, \penv \vdash e_{2}:k, \env_{3} \;\;\;
       \exists i \in 1{..}n \; k \lesssim k_{i}
       \end{array}}
      {\env_{1}, \penv \vdash e_{1}[e_{2}]:v_{i}, \env_{3}}
\end{array}
\end{array}
\]

A second form of refinement happens when we want to use an
\emph{unique} or \emph{open} table type in a context that expects a
\emph{closed} or \emph{regular} table type with a different shape.
This kind of refinement allows programmers to add optional fields
or merge existing fields.
To do that, Typed Lua includes a type coercion expression that
obeys the \textsc{T-COERCE} rule below:
\[
\begin{array}{c}
\mylabel{T-COERCE}\\
\dfrac{\env_{1}(n) \subtype t \;\;\;
       \env_{1}[n \mapsto t], \penv \vdash n_{e}:t_{1}, \env_{2}}
      {\env_{1}, \penv \vdash {<}t{>} \; n:t_{1}, \env_{2}}
\end{array}
\]

The rule \textsc{T-COERCE} allows our type system to type check the following example:
\begin{center}
\begin{tabular}{lll}
\multicolumn{3}{l}{$\mathbf{local} \; a:\{\}_{unique} = \{ \} \; \mathbf{in}$}\\
& \multicolumn{2}{l}{$a[``x"] \; {<}\String{>} = ``foo";$}\\
& \multicolumn{2}{l}{$a[``y"] \; {<}\String{>} = ``bar";$}\\
& \multicolumn{2}{l}{$\mathbf{local} \; b:\{``x":\String, ``y":\String \cup \Nil \}_{regular} =$}\\
& & \multicolumn{1}{l}{${<}\{``x":\String, ``y":\String \cup \Nil\}_{open}{>} \; a \; \mathbf{in} \; a[``z"] \; {<}\Integer{>} = 1$}
\end{tabular}
\end{center}

We can use $a$ to initialize $b$ because the coercion converts
the type of $a$ from $\{``x":\String, ``y":\String\}_{unique}$ to
$\{``x":\String, ``y":\String \cup \Nil\}_{open}$, and results in
$\{``x":\String, ``y":\String \cup \Nil\}_{closed}$,
which is a subtype of
$\{``x":\String, ``y":\String \cup \Nil\}_{regular}$, the type of $b$.
We can continue to refine the type of $a$ after aliasing it to $b$,
as it still holds an \emph{open} table.
At the end of this example, $a$ has type
$\{``x":\String, ``y":\String \cup \Nil, ``z":\Integer\}_{open}$.

We also need to make sure to close all \emph{unique} and \emph{open}
table types before we type check a nested scope.
The rule \textsc{T-FUNCTION3} illustrates this case:
\[
\begin{array}{c}
\mylabel{T-FUNCTION3}\\
\dfrac{closeall(\env_{1}[\vec{n} \mapsto \vec{t}]), \penv[\ret \mapsto r] \vdash s, \env_{2}}
      {\begin{array}{c}
       \env_{1}, \penv \vdash \mathbf{fun} \; (\vec{n{:}t}){:}r \; s:\vec{t} \times \Void \rightarrow r,\\
       openset(closeset(\env_{1}, fav(\mathbf{fun} \; (\vec{n{:}t}){:}r \; s)),rv(\mathbf{fun} \; (\vec{n{:}t}){:}r \; s))
       \end{array}}
\end{array}
\]

Rule \textsc{T-FUNCTION3} uses some auxiliary functions to change
the type of variables before type checking a nested scope and
also to change the type of assigned and referenced variables after
type checking a nested scope.
The function \emph{closeall} closes all \emph{unique} and \emph{open}
table types.
The function \emph{closeset} closes a given set of free assigned variables,
which is given by the function \emph{fav}.
The function \emph{openset} changes from \emph{unique} to \emph{open}
a given set of referenced variables, which is given by the function \emph{rv}.

This rule also extends the environment $\penv$, bounding the special
variable $\ret$ to the return type $r$.
Rule \textsc{T-RETURN} uses the type that is bound to $\ret$ in
$\penv$ to type check return statements:
\[
\begin{array}{c}
\mylabel{T-RETURN}\\
\dfrac{\env_{1} \vdash el:r_{1}, \env_{2} \;\;\;
       \penv(\ret) = r_{2} \;\;\;
       r_{1} \lesssim r_{2}}
      {\env_{1} \vdash \mathbf{return} \; el, \env_{2}}
\end{array}
\]

As an example, rule \textsc{T-FUNCTION3} prevents the following unsafe example to type check:
\begin{center}
\begin{tabular}{llll}
\multicolumn{4}{l}{$\mathbf{local} \; a:\{\}_{unique}, b:\{\}_{unique} = \{\}, \{\} \; \mathbf{in}$}\\
& \multicolumn{3}{l}{$\mathbf{local} \; f:\Integer \times \Void \rightarrow \Integer \times \Void =$}\\
& & \multicolumn{2}{l}{$\mathbf{fun} \; (x:\Integer):\Integer \times \Void$}\\
& & & \multicolumn{1}{l}{$b = a \;;\; \mathbf{return} \; x + 1$}\\
& \multicolumn{3}{l}{$\mathbf{in} \; a[``x"] \; {<}\Integer{>} = 1 \;;\; b[``x"] \; {<}\String{>} = ``foo" \;;\; f(a[``x"])_{s}$}
\end{tabular}
\end{center}

This example does not type check because we cannot add the field
$``x"$ to $b$, as its type is closed.
The assignment $b = a$ type checks because, at this point,
$a$ and $b$ have the same type: $\{\}_{closed}$.
Their type was closed by \emph{closeall} before type checking
the function body.
Their type would be restored to $\{\}_{unique}$ after type checking
the function body, but that assignment also triggers other two type changes.
First, the function \emph{fav} includes $b$ in the set of variables
that should be closed by \emph{closeset}.
Then, the function \emph{rv} includes $a$ in the set of variables
that should change from \emph{unique} to \emph{open} by \emph{openset}.
After declaring $f$, $a$ has type $\{\}_{open}$ and $b$ has type $\{\}_{closed}$,
so we can refine the type of $a$, but we cannot refine the type of $b$.

\subsection{Classes and objects}
\label{sec:cao}

Typed Lua also relies on the refinement of table types to type check
the idioms that Lua programmers use for incrementally building
classes and objects.
For instance, rule \textsc{T-METHOD3} illustrates how our type system
type checks method definitions:
\[
\begin{array}{c}
\mylabel{T-METHOD3}\\
\dfrac{\begin{array}{c}
       \env_{1}(n_{1}) = t_{s} \;\;\; t_{s} = \{k_{i}{:}v_{i}, ..., k_{n}{:}v_{n}\}_{unique|open}\\
       \env_{1}, \penv \vdash n_{2} : l, \env_{2} \;\;\;
       \not \exists i \in 1..n \; l \lesssim k_{i}\\
       closeall(\env_{1}[self \mapsto \Self, \vec{n} \mapsto \vec{t}, \self \mapsto t_{s}]),
       \penv[\ret \mapsto r] \vdash s, \env_{3}\\
       t_{o} = \{k_{i}{:}v_{i}, ..., k_{n}{:}v_{n}, l{:}\Const \; \Self \times \vec{t} \times \Void \rightarrow r\}_{unique|open}
       \end{array}}
      {\begin{array}{c}
       \env_{1}, \penv \vdash \mathbf{fun} \; n_{1}{:}n_{2} \; (\vec{n{:}t}){:}r \; s,\\
       openset(closeset(\env_{1}[n_{1} \mapsto t_{o}], fav(\mathbf{fun} \; (\vec{n{:}t}){:}r \; s)),rv(\mathbf{fun} \; (\vec{n{:}t}){:}r \; s))
       \end{array}}
\end{array}
\]

Rule \textsc{T-METHOD3} allows our type system to type check the
following example, which is a translation of the definition of the class
\texttt{Shape} from Section \ref{sec:oop}:
\begin{center}
\begin{tabular}{llll}
\multicolumn{4}{l}{$\mathbf{local} \; Shape{:}\{``x"{:}\Number, ``y"{:}\Number\}_{unique} = \{ [``x"] = 0.0, [``y"] = 0.0 \}$}\\
\multicolumn{4}{l}{$\mathbf{in}$}\\
& \multicolumn{3}{l}{$\mathbf{fun} \; Shape{:}new (x:\Number, y:\Number):\Self \times \Void$}\\
& & \multicolumn{2}{l}{$\mathbf{local} \; o:\Self = setmetatable(\{\}, \{ [``\string_\string_index"] = self \})$}\\
& & \multicolumn{2}{l}{$\mathbf{in} \; o[``x"] = x; \; o[``y"] = y; \; \mathbf{return} \; o$}\\
; & \multicolumn{3}{l}{$\mathbf{fun} \; Shape{:}move (x:\Number, y:\Number):\Void$}\\
& & \multicolumn{2}{l}{$self[``x"] = self[``x"] + x;$}\\
& & \multicolumn{2}{l}{$self[``y"] = self[``y"] + y;$}\\
& & \multicolumn{2}{l}{$\mathbf{return} \; \mathbf{nothing}$}
\end{tabular}
\end{center}

This example uses the type $\{``x":\Number, ``y":\Number\}_{unique}$ to
initialize the local variable $Shape$, which represents the class
that we are defining.
Then, it uses two method definitions to include $new$ and $move$ in our class.
These definitions refine the type of $Shape$, and it becomes the type below:
\begin{align*}
\{ & ``x":\Number, ``y":\Number,\\
   & \Const \; ``new":\Self \times \Number \times \Number \times \Void \rightarrow \Self \times \Void,\\
   & \Const \; ``move":\Self \times \Number \times \Number \times \Void \rightarrow \Void \}_{unique}
\end{align*}

Inside the definition of the methods \emph{new} and \emph{move},
we index variables that have type $\Self$.
This is possible because we include the rule \textsc{T-SELF}:
\[
\begin{array}{c}
\mylabel{T-SELF}\\
\dfrac{\env_{1}, \penv \vdash e:\Self, \env_{2} \;\;\;
       \env_{2}(\self) = t}
      {\env_{1}, \penv \vdash e:t, \env_{2}}
\end{array}
\]

When an expression has type $\Self$, our type system uses this
rule to produce the type that is bound to $\self$ in $\env$.
The variable $\self$ is a special variable that method definitions
and method calls use to bind the type of $\Self$ in the environment.

Inside the definition of the method \emph{new}, we use \emph{setmetatable}
to initialize $o$ with type $\Self$.
The rule \textsc{T-SETMETATABLE1} express this idea:
\[
\begin{array}{c}
\mylabel{T-SETMETATABLE1}\\
\dfrac{\env(n) = \Self}
      {\env, \penv \vdash setmetatable(\{\}, \{[``\string_\string_index"] = n\}):\Self, \env}
\end{array}
\]

In Section \ref{sec:oop} we also mentioned that our type system
uses \emph{setmetatable} to handle single inheritance.
Rule \textsc{T-SETMETATABLE2} allows refining the type of a new
class based on the type of an already defined class,
while rule \textsc{T-SETMETATABLE3} allows overriding a constructor:
\[
\begin{array}{c}
\begin{array}{c}
\mylabel{T-SETMETATABLE2}\\
\dfrac{\env(n) = \{k_{1}{:}v_{1}, ..., k_{n}{:}v_{n}\}_{closed}}
      {\env, \penv \vdash setmetatable(\{\}, \{[``\string_\string_index"] = n\}):\{k_{1}{:}v_{1}, ..., k_{n}{:}v_{n}\}_{open}, \env}
\end{array}
\\ \\
\begin{array}{c}
\mylabel{T-SETMETATABLE3}\\
\dfrac{\env_{1}, \penv \vdash e = t, \env_{2} \;\;\;
       t = \{k_{1}{:}v_{1}, ..., k_{n}{:}v_{n}\}_{closed} \;\;\;
       \env_{1}(n) = \Self \;\;\; \env_{1}(\sigma) \subtype t}
      {\env_{1}, \penv \vdash setmetatable(e, \{[``\string_\string_index"] = n\}):\Self, \env_{2}[\sigma \mapsto t]}
\end{array}
\end{array}
\]

After we define our class, we can use it to create instances
of this class and call their methods.
Rule \textsc{T-INVOKE1} handles the case where method calls
are expressions that produce multiple values:
\[
\begin{array}{c}
\mylabel{T-INVOKE1}\\
\dfrac{\begin{array}{c}
       \env_{1}, \penv \vdash e:t_{s}, \env_{2}\\
       \env_{2}[\sigma \mapsto t_{s}], \penv \vdash e[n]:\Const \; r_{1} \rightarrow r_{2}, \env_{3}\\
       \env_{3}[\sigma \mapsto t_{s}], \penv \vdash el:r_{3}, \env_{4} \;\;\;
       t_{s} \times r_{3} \lesssim r_{1}
       \end{array}}
      {\env_{1}, \penv \vdash e{:}n(el)_{m}:[\sigma \mapsto t]r_{2}, \env_{4}}
\end{array}
\]

We also use the rule \textsc{T-INVOKE1} as the base case for the rules
that handle the cases where method calls are either statements
or expressions that produce only one value:
\[
\begin{array}{c}
\begin{array}{c}
\mylabel{T-STMINVOKE1}\\
\dfrac{\env_{1}, \penv \vdash e{:}n(el)_{m}:r, \env_{2}}
      {\env_{1}, \penv \vdash e{:}n(el)_{s},\env_{2}}
\end{array}
\;
\begin{array}{c}
\mylabel{T-EXPINVOKE1}\\
\dfrac{\env_{1}, \penv \vdash e{:}n(el)_{m}:r, \env_{2}}
      {\env_{1}, \penv \vdash e{:}n(el)_{e}:first(r), \env_{2}}
\end{array}
\end{array}
\]

The rule \textsc{T-STMINVOKE1} discards the produced values,
while the rule \textsc{T-EXPINVOKE1} uses the predicate \emph{first} to
ensure that only one value is produced.

As an example, assuming that the object $o$ is in the environment and
has the type of the class $Shape$, the method call
\[
o{:}move(10, 10)_{m}
\]
type checks through the rule \textsc{T-INVOKE1}, because
\[
Shape \times 10 \times 10 \times \Nil{*} \lesssim Shape \times \Number \times \Number \times \Void
\]
assuming that $Shape$ is an alias to the type of the class $Shape$.
Note that rule \textsc{T-INVOKE1} uses the object type to bind
the type $\Self$ before type checking a method call.

\subsection{Filters and projections}
\label{sec:fap}

In Section \ref{sec:unions} we mentioned that our type system 
includes union types to encode three common Lua idioms:
the use of optional values, the overloading based on the tags of
input parameters, and the overloading on the return type of functions.
Now, we will discuss how our type system uses the $\mathbf{or}$
operator to handle optional values, how it uses filter types to
discriminate unions of first-level types, and how it uses
projection types to discriminate overloaded return types,
which are unions of second-level types.

Typed Lua includes five typing rules for handling the $\mathbf{or}$
logical operator and its common idioms:
\[
\begin{array}{c}
\begin{array}{c}
\mylabel{T-OR1}\\
\dfrac{\env_{1}, \penv \vdash e_{1}:t, \env_{2} \;\;\;
       \Nil \not\lesssim t \;\;\;
       \False \not\lesssim t}
      {\env_{1}, \penv \vdash e_{1} \; \mathbf{or} \; e_{2}:t, \env_{2}}
\end{array}
\\ \\
\begin{array}{c}
\mylabel{T-OR2}\\
\dfrac{\env_{1}, \penv \vdash e_{1}:\Nil, \env_{2} \;\;\;
       \env_{2}, \penv \vdash e_{2}:t, \env_{3}}
      {\env_{1}, \penv \vdash e_{1} \; \mathbf{or} \; e_{2}:t, \env_{3}}
\end{array}
\\ \\
\begin{array}{c}
\mylabel{T-OR3}\\
\dfrac{\env_{1}, \penv \vdash e_{1}:\False, \env_{2} \;\;\;
       \env_{2}, \penv \vdash e_{2}:t, \env_{3}}
      {\env_{1}, \penv \vdash e_{1} \; \mathbf{or} \; e_{2}:t, \env_{3}}
\end{array}
\\ \\
\begin{array}{c}
\mylabel{T-OR4}\\
\dfrac{\env_{1}, \penv \vdash e_{1}:\Nil \cup \False, \env_{2} \;\;\;
       \env_{2}, \penv \vdash e_{2}:t, \env_{3}}
      {\env_{1}, \penv \vdash e_{1} \; \mathbf{or} \; e_{2}:t, \env_{3}}
\end{array}
\\ \\
\begin{array}{c}
\mylabel{T-OR5}\\
\dfrac{\env_{1}, \penv \vdash e_{1}:t_{1}, \env_{2} \;\;\;
       \env_{2}, \penv \vdash e_{2}:t_{2}, \env_{3}}
      {\env_{1}, \penv \vdash e_{1} \; \mathbf{or} \; e_{2}:filter(filter(t_{1}, \Nil), \False) \cup t_{2}, \env_{3}}
\end{array}
\end{array}
\]

Rule \textsc{T-OR1} is the rule that defines the short circuit.
We use the consistent-subtyping relation in this rule to guarantee that
the type system checks the second expression when the first one
has the dynamic type, as it can be hiding a false value.

Rules \textsc{T-OR2}, \textsc{T-OR3}, and \textsc{T-OR4} guarantee
that the final result is the type of the second expression, because the
first one is certainly a false value.

Rule \textsc{T-OR5} is the most general rule, but it is also
the rule that handles the common $\mathbf{or}$ idioms.
It uses the auxiliary function \emph{filter} to filter possible false
values that might be part of the type of the first expression.
We can use pattern matching to the define the recursive function
\emph{filter} as follows:
\begin{align*}
filter(t_{1} \cup t_{2}, t_{1}) & = filter(t_{2}, t_{1})\\
filter(t_{1} \cup t_{2}, t_{2}) & = filter(t_{1}, t_{2})\\
filter(t_{1} \cup t_{2}, t_{3}) & = filter(t_{1}, t_{3}) \cup filter(t_{2}, t_{3})\\
filter(t_{1}, t_{2}) & = t_{1}
\end{align*}

Rule \textsc{T-OR5} allows our type system to type check the following example:
\begin{center}
\begin{tabular}{ll}
\multicolumn{2}{l}{$\mathbf{local} \; x:\String \cup \Nil = \mathbf{nothing} \; \mathbf{in}$}\\
& \multicolumn{1}{l}{$\mathbf{local} \; y:\String = x \; \mathbf{or} \; ``Hello"$}
\end{tabular}
\end{center}

Without the \emph{filter} function,
the expression $x \; \mathbf{or} \; ``Hello"$ would have type
$\String \cup \Nil \cup ``Hello"$.
The \emph{filter} function removes the type $\Nil$ from the result,
leaving the type $\String \cup ``Hello"$.
This means that type checking the expression $x \; \mathbf{or} \; ``Hello"$
results in the type $\String$, because union types are disjoint and
$``Hello" \lesssim \String$.

Another common idiom that programmers use in Lua is to overload
the type of function parameters, and use the function \texttt{type}
to execute different actions according to their types.
The rule \textsc{T-IF2} shows the case where our type system
discriminates an union of first-level types based on the tag \texttt{string}:
\[
\begin{array}{c}
\mylabel{T-IF2}\\
\dfrac{\begin{array}{c}
       \env_{1}(n) = t_{1} \cup t_{2}\\
       closeall(\env_{1}[n \mapsto \phi(t,\String)]), \penv \vdash s_{1}, \env_{2} \\
       closeall(\env_{1}[n \mapsto \phi(t,filter(t, \String))), \penv \vdash s_{2}, \env_{3}\\
       \env_{4} = openset(closeset(\env_{1}[n \mapsto t], fav(s_{1}) \cup fav(s_{2})),rv(s_{1}) \cup rv(s_{2}))
      \end{array}}
      {\env_{1}, \penv \vdash \mathbf{if} \; type(n) == ``string" \; \mathbf{then} \; s_{1} \; \mathbf{else} \; s_{2}, \env_{4}}

\end{array}
\]

In Typed Lua, \emph{type} is a primitive that triggers a type change.
In the rule \textsc{T-IF2}, the type of a variable $n$ changes from
$t_{1} \cup t_{2}$ to $\phi(t_{1} \cup t_{2},\String)$ inside the
$\mathbf{if}$ branch, and it changes the type of a variable $n$ from
$t_{1} \cup t_{2}$ to $\phi(t,filter(t_{1} \cup t_{2},\String))$
inside the $\mathbf{else}$ branch.

Rule \textsc{T-IF2} changes the type of a local variable $n$ to a
filter type because it gives the discriminated type when we use $n$ as
an expression, and it restores the original type when we use $n$
in an assignment.
In Section \ref{sec:refinement} we mentioned that rule \textsc{T-IDREAD}
uses the function \emph{read} to produce the discriminated type,
while rule \textsc{T-IDWRITE} uses the function \emph{write} to
restore the original type.
Now, we will give the definition of these functions.

We can define \emph{read} as follows:
\begin{align*}
read(\penv, \phi(t_{1},t_{2})) & = t_{2}\\
read(\penv, \pi_{i}^{x}) & = proj(\penv, x, i)\\
read(\penv, t) & = t
\end{align*}

The function \emph{read} uses the auxiliary function \emph{proj}
to project a union of first-level types, based on an union of
second-level types and an index from a projection type.
In this section, we will discuss how our type system uses
projection types to handle overloaded return types.

We can define \emph{write} as follows:
\begin{align*}
write(\phi(t_{1},t_{2})) & = t_{1}\\
write(t) & = t
\end{align*}

As an example, assuming that \emph{rep} is in the environment and has type
$\String \times \Integer \times \String \cup \Nil \times \Void \rightarrow \String \times \Void$,
the following code type checks through rule \textsc{T-IF2}:
\begin{center}
\begin{tabular}{llll}
\multicolumn{4}{l}{$\mathbf{local} \; o:\String \times \String \cup \Integer \times \Void \rightarrow \String \times \Void =$}\\
& \multicolumn{3}{l}{$\mathbf{fun} \; (a:\String, b:\String \cup \Integer):\String \times \Void$}\\
& & \multicolumn{2}{l}{$\mathbf{local} \; r:\String = ``" \; \mathbf{in}$}\\
& & & \multicolumn{1}{l}{$\mathbf{if} \; type(b) == ``string" \; \mathbf{then} \; r = a \;{..}\;b \; \mathbf{else} \; r = rep(a, b)_{e}\; ;$}\\
& & & \multicolumn{1}{l}{$\mathbf{return} \; r$}\\
\multicolumn{4}{l}{$\mathbf{in} \; o(``foo", 2)_{s}$}
\end{tabular}
\end{center}

In this example, the type of $b$ changes to
$\phi(\String \cup \Integer, \String)$ inside the $\mathbf{if}$ branch, and
it changes to $\phi(\String \cup \Integer, \Integer)$ inside the $\mathbf{else}$ branch.
Thus, reading $b$ results in the type $\String$ inside the $\mathbf{if}$ branch,
and it results in the type $\Integer$ inside the $\mathbf{else}$ branch.
Outside the condition, $b$ has its original type: $\String \cup \Integer$.

Typed Lua also includes similar rules to handle the tags \texttt{nil},
\texttt{boolean}, and \texttt{number}.
There is also a similar rule for handling the tag \texttt{integer}, but
it is limited to Lua 5.3, as it depends on the function \texttt{math.type}.
This function appears only in Lua 5.3 and it returns the tag \texttt{integer}
when its input parameter is a number that has an integer representation,
the tag \texttt{float} when its input parameter is a number that has a
floating point representation, or \texttt{nil} otherwise.

Lua programmers also overload the return type of functions to denote errors,
and our type system uses projection types to handle this idiom.

As an example, assuming that \emph{idiv} and \emph{print} are in the
environment with the respective types
$\Integer \times \Integer \times \Void \rightarrow \Integer \times \Integer \times \Void \sqcup \Nil \times \String \times \Void$
and
$\Value{*} \rightarrow \Void$,
the following code type checks in our type system:
\begin{center}
\begin{tabular}{ll}
\multicolumn{2}{l}{$\mathbf{local} \; q:\pi_{1}^{x}, r:\pi_{2}^{x} = idiv(1, 2)_{m}^{x} \; \mathbf{in}$}\\
& \multicolumn{1}{l}{$\mathbf{if} \; q \; \mathbf{then} \; print(q + r)_{s} \; \mathbf{else} \; print(``ERROR: " \; .. \; r)_{s}$}
\end{tabular}
\end{center}

There are three typing rules involved in the type checking of this example,
which we will explain now.

First, that example uses rule \textsc{T-EXPLIST6} for type checking
$idiv(1, 2)_{m}^{x}$:
\[
\begin{array}{c}
\mylabel{T-EXPLIST6}\\
\dfrac{\begin{array}{c}
       \env_{1}, \penv \vdash me^{x}:r, \env_{2}\\
       r = t_{1} \times ... \times t_{n} \times \Void \sqcup t_{1}' \times ... \times t_{n}' \times \Void
       \end{array}}
      {\env_{1}, \penv \vdash me^{x}:\pi_{1}^{x} \times ... \times \pi_{n}^{x} \times \Nil{*}, \env_{2}, (x,r)}
\end{array}
\]

Rule \textsc{T-EXPLIST6} uses the auxiliary relation
$\env_{1}, \penv \vdash el : r_{1}, \env_{2}, (x,r_{2})$.
This relation means that given a type environment $\env_{1}$ and
a projection environment $\penv$, an expression list $el$ has type
$r_{1}$ and produces a new type environment $\env_{2}$ and
produces a pair $(x,r_{2})$.
This pair means that the last expression of an expression list $el$
produces a second-level type $r_{2}$ that should be bound to
a variable $x$ in the projection environment,
as the resulting type of this expression is a tuple of projection
types $\pi_{i}^{x}$.

Our type system uses this pair to allow rule \textsc{T-LOCAL} to bound
a second-level type $r_{2}$ to a variable $x$ in $\penv$,
after rule \textsc{T-LOCAL} checks whether the type of an expression
list $el$ matches the types in the annotations:
\[
\begin{array}{c}
\mylabel{T-LOCAL}\\
\dfrac{\env_{1}, \penv \vdash el:r_{1}, \env_{2}, (x,r_{2}) \;\;\;
       r_{1} \lesssim \vec{t} \times \Value{*} \;\;\;
       \env_{2}[\vec{n} \mapsto \vec{t}], \penv[x \mapsto r_{2}] \vdash s, \env_{3}}
      {\env_{1}, \penv \vdash \mathbf{local} \; \vec{n{:}t} = el \; \mathbf{in} \; s, \env_{3} - \{\vec{n} \mapsto \vec{t}\}}
\end{array}
\]

After type checking the statement $s$, rule \textsc{T-LOCAL} produces a
new environment without the variables that it introduced before type checking $s$.

Introducing a variable $x$ in the projection environment allows our
type system to discriminate projection types $\pi_{i}^{x}$.
The rule \textsc{T-IF3} shows the case where our type system
discriminates a projection type based on the tag \texttt{nil}:
\[
\begin{array}{c}
\mylabel{T-IF3}\\
\dfrac{\begin{array}{c}
       \env_{1}(n) = \pi_{i}^{x} \;\;\; \penv(x) = r\\
       closeall(\env_{1}), \penv[x \mapsto fpt(r,\Nil,i)] \vdash s_{1}, \env_{2} \\
       closeall(\env_{1}), \penv[x \mapsto gpt(r,\Nil,i)] \vdash s_{2}, \env_{3} \\
       \env_{4} = openset(closeset(\env_{1}, fav(s_{1}) \cup fav(s_{2})),rv(s_{1}) \cup rv(s_{2}))
      \end{array}}
      {\env_{1}, \penv \vdash \mathbf{if} \; n \; \mathbf{then} \; s_{1} \; \mathbf{else} \; s_{2}, \env_{4}}
\end{array}
\]

Rule \textsc{T-IF3} uses the auxiliary functions \emph{fpt} and \emph{gpt}
to filter a projection $x$, affecting all variables that bind to the same projection.
For instance, our previous example type checks through rule \textsc{T-IF3},
because it makes the rule \textsc{T-IF3} use the function call
\[
fpt(\Integer \times \Integer \times \Void \sqcup \Nil \times \String \times \Void, \Nil, 1)
\]
to discriminate the projection $x$ to the single tuple
$\Integer \times \Integer \times \Void$ inside the $\mathbf{if}$ branch,
and the function call
\[
gpt(\Integer \times \Integer \times \Void \sqcup \Nil \times \String \times \Void, \Nil, 1)
\]
to discriminate the projection $x$ to the single tuple
$\Nil \times \String \times \Void$ inside the $\mathbf{else}$ branch.
Thus, reading $q$ and $r$ projects $\pi_{1}^{x}$ to $\Integer$ and
$\pi_{2}^{x}$ to $\Integer$ inside the $\mathbf{if}$ branch,
but it projects $\pi_{1}^{x}$ to $\Nil$ and $\pi_{2}^{x}$ to $\String$
inside the $\mathbf{else}$ branch.
Outside the condition, $q$ and $r$ use the original projection, that is,
they project to $\Integer \cup \Nil$ and $\Integer \cup \String$, respectively.

\subsection{Arithmetic operations}
\label{sec:arith}

Lua has operator overloading, and allows programmers to redefine
the behavior of some operations.
For instance, programmers can use metatables to redefine the
behavior of arithmetic operations.
Even though Typed Lua does not support operator overloading yet,
it includes typing rules that allow programmers to use the
dynamic type when they are using overloaded operations.
The following typing rules show how Typed Lua uses the dynamic type
to handle the overloading of arithmetic operations:
\[
\begin{array}{c}
\begin{array}{c}
\mylabel{T-ARITH5}\\
\dfrac{\env_{1}, \penv \vdash e_{1}:\Any, \env_{2} \;\;\;
       \env_{2}, \penv \vdash e_{2}:t, \env_{3}}
      {\env_{1}, \penv \vdash e_{1} + e_{2}:\Any, \env_{3}}
\end{array}
\\ \\
\begin{array}{c}
\mylabel{T-ARITH6}\\
\dfrac{\env_{1}, \penv \vdash e_{1}:t, \env_{2} \;\;\;
       \env_{2}, \penv \vdash e_{2}:\Any, \env_{3}}
      {\env_{1}, \penv \vdash e_{1} + e_{2}:\Any, \env_{3}}
\end{array}
\end{array}
\]

The rule \textsc{T-ARITH5} allows type checking the following
example:
\begin{center}
\begin{tabular}{l}
$\mathbf{local} \; x{:}\Any = 1 \; \mathbf{in} \; x = x + 1$
\end{tabular}
\end{center}

This example is safe, but the following it is not:
\begin{center}
\begin{tabular}{l}
$\mathbf{local} \; x{:}\Integer, \;y{:}\Any = 1 \; \mathbf{in} \; x = x + y$
\end{tabular}
\end{center}

Although this last example is not safe, it shows that optional
type systems still preserve the flexibility of dynamically
typed languages along with the benefits of static type checking.
